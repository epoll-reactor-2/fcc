\documentclass[leqno, 12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[polish]{babel}
\usepackage{polski}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{caption}
\usepackage[dvipsnames]{xcolor}
\usepackage[fleqn]{amsmath}  % Aligned to left equations.
\usepackage[a4paper, total={7.5in, 9.5in}]{geometry}
\usepackage{tabularx}
\usepackage{geometry}
\usepackage{syntax}
\usepackage{fancyhdr}
\usepackage{mathpartir}
\usepackage{listings}
\usepackage[autosize]{dot2texi}
\usepackage{tikz}
\usepackage{drawstack}

\usetikzlibrary{automata}
\usetikzlibrary{positioning}
\usetikzlibrary{shapes}
\usetikzlibrary{arrows}
\usetikzlibrary{chains}
\usetikzlibrary{calc}

\algnewcommand\algorithmicswitch{\textbf{switch}}
\algnewcommand\algorithmiccase{\textbf{case}}
\algnewcommand\algorithmicassert{\texttt{assert}}
\algnewcommand\Assert[1]{\State \algorithmicassert(#1)}%
% New "environments"
\algdef{SE}[SWITCH]{Switch}{EndSwitch}[1]{\algorithmicswitch\ #1\ \algorithmicdo}{\algorithmicend\ \algorithmicswitch}%
\algdef{SE}[CASE]{Case}{EndCase}[1]{\algorithmiccase\ #1}{\algorithmicend\ \algorithmiccase}%
\algtext*{EndSwitch}%
\algtext*{EndCase}%

\lstset{
    xleftmargin    = .2\textwidth,
    xrightmargin   = .2\textwidth,
    basicstyle     = \footnotesize\ttfamily,
    breaklines     = true,
    linewidth      = 16cm
}

\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering  \let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft \let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

\setlength{\textwidth}{7.5in}
\setlength{\textheight}{10in}

\newcommand{\spacing}{\vskip 0.5cm}

\let\titleoriginal\title           % save original \title macro
\renewcommand{\title}[1]{          % substitute for a new \title
    \titleoriginal{#1}%            % define the real title
    \newcommand{\thetitle}{#1}     % define \thetitle
}

\lstset{
	firstnumber = 0,
	tabsize     = 4,
	frame       = single,
	linewidth   = 1.2\textwidth,
	xleftmargin = 0cm
}

\captionsetup{
    format          = plain,
    singlelinecheck = false,
    justification   = raggedright,
    margin          = {.5cm, 0cm}
}

\counterwithin{figure}{section}
\counterwithin{table}{section}

\title{Kompilator języka strukturalnego}
\author{David Korenchuk}
\date{August, 23, 2023}

\begin{document}
    \pagestyle{fancy}
    \lhead{\leftmark}
    \rhead{\thetitle}
    
    \setlength{\parindent}{0pt}

    \maketitle
	
	%% 1.   Wprowadzenie
	%% 2.   Teoria
	%% ...  Opis lex
	%% ...  Opis parse
	%% ...  Opis codegen
	%% ...  Opis interpreter
	%% N.   Podsumowanie. Co było zrobione
	
	\section{Wprowadzenie}
	
		Człowiek posługuje się językami werbalnymi, aby komunikować z innymi ludźmi. Za pomocą
		języka polskiego albo angielskiego można wyrazić myśl, ale zazwyczaj w sposób niejednoznaczny,
		bo jesteśmy przyzwyczajeni do tego, że każde zdanie może być wyrażone na wiele sposobów. Natomiast,
		aby umożliwić komunikację pomiędzy człowiekiem a komputerem, te zdania muszą być dość mocno
		sprecyzowane, aby móc je wykonać w sposób deterministyczny.
		\\
		
		Celem niniejszej pracy jest pokazanie technik, które są używane do umożliwiania takiego rodzaju
		komunikacji. Dalsza część pracy zawiera opis każdego z etapów tworzenia języka programowania
		strukturalnego. 
	
	\section{Historia}
		
		Potrzeba automatyzacji pracy intelektualnej istniała zawsze. Dlatego od dawna człowiek próbuje
		znaleźć metody do tego. Niżej jest krótkie podsumowanie powstania informatyki.
		\\

		\begin{itemize}
			\item W \textbf{IX} wieku
				przez irańskiego matematyka al Kindi wieku został stworzony system szyfrowania informacji na
				podstawie zliczania ilości liter w tekscie.

			\item W \textbf{XVII} wieku powstał suwak logarytmiczny, potrzebny do ułatwienia działań
				matematycznych.
			
			\item W tym samym \textbf{XVII} wieku powstał jeden z pierszych kalkulatorów mechanicznych
				\textbf{Pascalina}. Jest to narzędzie do wykonania operacji arytmetycznych na podstawie
				ruchu koł zębatych i innych części.
				
			\item W \textbf{XVIII} wieku Charlesa Babbage stworzył mechaniczną \textbf{maszynę
				różnicową} do tworzenia dużych tabeli logarytmicznych, które do tej pory człowiek
				musiał wyliczać ręcznie.
			
			\item W 1847 roku George Boole wyprowadził nowy rozdział algebry: \textbf{algebrę Boole'a},
				na podstawie której później został zaprojektowany pierwszy klasyczny komputer.
			
			\item W 1930 roku Vannevar Bush stworzył \textbf{analizator różnicowy} do rozwiązania
				równań różnicowych metodą całkowania.
			
			

		\end{itemize}

		\newpage
		
	\section{Teoria}

		\subsection{Języki formalne}

			Według teorii automatów, automat -- jest to jednostka wykonawcza. Jednostki te, zależnie od swojej
			struktury i tego, jaki \textbf{język formalny} oni mogą obrobić, dzielą się na klasy.
			\\
			
			Klasy te opisane są \textbf{hierarchią Chomsky’ego}. Mówi ona o tym, że języki formalne dzielą się na
			4 typy:
			\begin{itemize}
				\item Typ 3 -- języki regularne
				\item Typ 2 -- języki bezkontekstowe
				\item Typ 1 -- języki kontekstowe
				\item Typ 0 -- języki rekurencyjnie przeliczalne
			\end{itemize}
			
			\spacing

			Jako przykład języka typu 3 według hierarchii Chomsky'ego można podać wyrażenia regularne. Język ten
			opisuje się automatem skończonym deterministycznym (DFA). Bardziej szczegółowo wyrażenia regularne będą
			rozpatrzone w opisaniu analizy leksykalnej.
			
		\subsection{Klasyfikacja gramatyczna}

			Niniejszy język nie może być odniesiony do żadnej z klas hierarchii Chomsky'ego, chociaż jest on
			językiem regularnym. Tak jest dlatego, że można napisać gramatycznie poprawny kod, który jednak prowadzi
			do błędów kontekstowych i logicznych. Naprzykład 
			
			\spacing
			
			\begin{lstlisting}[caption={}, label={lst:ambigous-production}]
void f() {
	return argument + 1;
}
		\end{lstlisting}

			\spacing
			
			Kolejną z przyczyn niemożliwości odniesienia naszego języka do jednej z klas hierarchii Chomsky'ego
			jest niejednoznaczność konstrukcji językowych. Przykład niżej pokazuje, że nie można jednoznacznie
			stwierdzić, czy \texttt{data * d} jest deklaracją zmiennej albo operatorem mnożenia dwóch zmiennych.
			Aby móc poprawnie prowadzić analizę składniową, musimy zadbać o rozróżnienie kontekstu.

			\spacing
			
			\begin{lstlisting}[caption={}, label={lst:ambigous-production}]
void f() {
	data *d;
}
			\end{lstlisting}

			\newpage

	\section{Analiza leksykalna}

		Jednym ze sposobów na sprowadzanie kodu źródłowego do postaći listy tokenów jest narzędzie flex.
		Przyjmuje ono zestaw reguł w postaći wyrażeń regularnych, według których
		działa rozbicie tekstu wejściowego. Można jednak ominąć lex i zaimplemenetować lexer ręcznie, ale
		ta praca nie skupia się na tym.

		\subsection{Wyrażenia regularne}

			Wyrażenie regularne -- łańcuch znaków, zawierający pewne polecenia do wyszukiwania tekstu.
			\\

			Mówimy, że wyrażenie regularne określone nad alfabetem $\Sigma$, jeżeli zachodzą następujące
			warunki:

			\begin{itemize}
				\item $\emptyset$ -- wyrażenie regularne, reprezentujące pusty zbiór.
				\item $\epsilon$ -- wyrażenie regularne, reprezentujące pusty łańcuch.
				\item $\forall_{a \in \Sigma}$, $a$ reprezentuje jeden znak.
				\item Warunek indukcyjny: jeżeli $R_1, R_2$ -- wyrażenia regularne, $(R_1 R_2)$
				      stanowi konkatenację $R_1$ i $R_2$.
		      	\item Warunek indukcyjny: jeżeli $R$ -- wyrażenie regularne, $R*$ stanowi domknięcie Kleene'ego. 
			\end{itemize}

			\spacing

			W rzeczywistości, takich zasad może być więcej.
			\\

			Zazwyczaj wyrażenie regularne jest realizowane za pomocą DFA (Deterministic finite automaton,
			Deterministyczny automat skończony).
			Lex sprowadza podany zbiór zasad do takiego automatu.
			\\

			Podamy przykład automatu dla wyrażenia \texttt{-?[0-9]+}
			
			\spacing
			\spacing

			\begin{center}
			\begin{tikzpicture}[node distance=4cm]
				\node[state, initial, accepting] (0) {0};
				\node[state, right of=0]         (1) {1};
				\node[state, right of=1]         (2) {2};
				\draw
				(0) edge[       bend left ]             (1)
				(0) edge[below, bend right] node{$-$}   (1)
				(1) edge[below            ] node{$0-9$} (2)
				(2) edge[loop below       ] node{$0-9$} (2)
				;
			\end{tikzpicture}
			\end{center}
			
			Aby odśledzić wykonane kroki, można wypełnić tabelę przejść pomiędzy stanami. Podamy przykład dla
			łańcucha \texttt{-22}

			\spacing
			\spacing

		\begin{center}
			\setlength{\tabcolsep}{0.5em}
			\renewcommand{\arraystretch}{1.2}
			\begin{tabular}{ | L{3cm} | L{4cm} | }
				\hline
				Biężący stan        & Akcja \\
				\hline
				\textbf{0}          & zaakceptować - \\
				\hline
				0, \textbf{1}       & zaakceptować 2 \\
				\hline
				0, 1, \textbf{2}    & zaakceptować 2 \\
				\hline
			\end{tabular}
		\end{center}
		
		\newpage

	\subsection{Flex}

		Flex jest narzędziem projektu GNU. Pozwala ono w wygodny sposób podać listę reguł dla analizy
		leksykalnej (ang. Scanning). Flex jest mocno powiązany z językiem C, dlatego program w flex'u
		korzysta z konstrukcji języka C. Pokażemy przykład użycia flex'u
		
		\spacing
		
		\begin{lstlisting}
%{
#include "portrzebny-do-analizy-plik.h"

/* Kod w jezyku C. */
%}

/* Opcje flex */
%option noyywrap nounput noinput
%option yylineno

%% /* Reguly w postaci wyrazen regularnych. */

/*********************************************************************/
/* Wzorzec                   | Akcja przy znalezieniu takiego wzorcu */
/*********************************************************************/
-?[0-9]+                       LEX_CONSUME_WORD(TOK_INTEGRAL_LITERAL)
-?[0-9]+\.[0-9]+               LEX_CONSUME_WORD(TOK_FLOATING_POINT_LITERAL)
\"([^\"\\]*(\\.[^\"\\]*)*)\"   LEX_CONSUME_WORD(TOK_STRING_LITERAL)
\'.\'                          LEX_CONSUME_WORD(TOK_CHAR_LITERAL)

.                              { /* Znaleziony niewiadomy znak.
                                    Zglosic blad.
                                  */ }
%%
		\end{lstlisting}

		\spacing
		
		Zauważmy, że flex próbuje szukać wzorców w tekscie dokładnie w takiej kolejności, która jest podana w
		jego kodzie. Dlatego często robią ostatnią regułe z wyrażeniem regularnym ".", który akceptuje
		dowolny znak, i umieszczają tam komunikat o błędzie.
		\\

		W naszym przypadku, lex generuje kod, który gromadzi wszystkie znalezione lexemy do tablicy.

		\newpage

	\section{Analiza składniowa}
		
		\subsection{Definicja}

			Mając listę składników elementarnych wejściowego programu, jesteśmy w stanie przejść do
			następnego etapu kompilacji -- analizy składniowej. Jest to proces generacji struktury
			drzewiastej, a mianowicie AST (Abstract Syntax Tree).
			\spacing
			
			Wynikiem działania analizy składniowej zawsze jest \textbf{jedno} drzewo AST. Może zawieraić ono
			definicje wszystkich funkcji.
			\\
		
			AST może być stworzony po zdefiniowaniu gramatyki regularnej danego języka. Stosuje się
			do tego notacja BNF (Backus–Naur form). Pełny opis gramatyki pokazany jest w końcu pracy. Pokażemy
			tylko kilka przykładów:
			
			\spacing

		    \setlength{\grammarindent}{12em}

		    \begin{grammar}
		        <program> ::= ( <function-decl> | <structure-decl> )*

		        <var-decl> ::= <type> ( \tt{*} )* <id> \tt{=} <logical-or-stmt> \tt{;}

		        <stmt> ::= <block-stmt>
		        \alt <selection-stmt>
		        \alt <iteration-stmt>
		        \alt <jump-stmt>
		        \alt <decl>
		        \alt <expr>
		        \alt <assignment-stmt>
		        \alt <primary-stmt>
			\end{grammar}
			
			\spacing
			
			W przypadku wyrażeń arytmetycznych, AST także jednoznacznie określa za pomocą produkcji
			gramatyki BNF priorytet operacji
			arytmetycznych. Naprzykład, mając wyrażenie \ \texttt{1 + 2 * 3 + 4}, drzewo syntaksyczne
			będzie skonstruowane zgodnie z prawami arytmetyki, co pozwala nie trzymać w AST żadnych
			informacji o nawiasach. Widać, że aby zastosować produkcję \textit{$<$additive-stmt$>$},
			najpierw musi być zastosowana następna produkcja \textit{$<$multiplicative-stmt$>$}.
			\\

			Pomocnicza przy prowadzeniu analizy jest \textbf{tablica parsingu}. Jest to zbiór
			konkretnych przejść pomiędzy produkcjami. Pomaga ona w zrozumieniu, jaką
			produkcję zastosować mając dany nieterminal. Zauważmy, że w tabelę są wpisane produkcje bez
			alternatyw, i każde przejście gramatyczne określone jednoznacznie.
			\\
			
			Aby zbudować tą tablicy, możemy użyć zasady
			\textbf{First \& Follow}. Tutaj \textbf{First} to zbiór terminalnych symboli, które mogą pojawić
			się jako
			pierwsze w ciągu znaków wygenerowanym przez daną nieterminalną symbol w gramatyce,
			a \textbf{Follow} to
			zbiór terminalnych symboli, które mogą wystąpić bezpośrednio po danym nieterminalnym symbolu
			w dowolnym ciągu znaków wygenerowanym przez gramatykę.
			\\
			
			Podamy gramatykę dla przykładu powyżej (\texttt{1 + 2 * 3 + 4}). Musimy wprowadzić dwa poziomy
			priorytetów, aby prawidłowo zachować kolejność operacji mnożenia i dodawania.
			\\

			\begin{grammar}
		        <additive-stmt> ::= <multiplicative-stmt>
		        \alt <multiplicative-stmt> \tt{"+"} <additive-stmt>
		        \alt <multiplicative-stmt> \tt{"-"} <additive-stmt>

		        <multiplicative-stmt> ::= <prefix-unary-stmt>
		        \alt <prefix-unary-stmt> \tt{"*"} <multiplicative-stmt>
		        \alt <prefix-unary-stmt> \tt{"/"} <multiplicative-stmt>
		        \alt <prefix-unary-stmt> \tt{"%"} <multiplicative-stmt>
			\end{grammar}
			
			\spacing

			\begin{center}
				\setlength{\tabcolsep}{0.5em}
				\renewcommand{\arraystretch}{1.5}
				\begin{tabular}{ L{5cm} L{3cm} L{4cm} }
					                          & \textbf{First} & \textbf{Follow} \\
					$<$additive-stmt$>$       & 0-9            & \textbf{+}, \textbf{-} \\
					$<$multiplicative-stmt$>$ & 0-9            & \textbf{*}, \textbf{/} \\
					$<$prefix-unary-stmt$>$   & 0-9            & $\epsilon$ \\
				\end{tabular}
			\end{center}

			\spacing

			\begin{center}
				\setlength{\tabcolsep}{0.5em}
				\renewcommand{\arraystretch}{1.5}
				\begin{tabular}{ | L{4.1cm} | L{2cm} | L{2cm} | L{2cm} | L{2cm} | L{2cm} | L{2cm} | }
                  	\hline
                  	       & 0-9    & +    & -    & *    & /    & \$ \\
                  	\hline
              	 	$<$additive-stmt$>$
              	 	       &        & $<$mul$>$ + $<$add$>$
              	 	                & $<$mul$>$ - $<$add$>$
              	 	                & & & $<$mul$>$ \\
                  	\hline
                  	$<$multiplicative-stmt$>$ 
                  		   &        & & & $<$una$>$ * $<$mul$>$
                  		                & $<$una$>$ / $<$mul$>$
                  		                & $<$una$>$ \\
                  	\hline
                  	$<$prefix-unary-stmt$>$
                  	       & 0-9 & & & & & \\
                  	\hline
				\end{tabular}
			\end{center}

			\spacing

			\begin{center}
			\begin{tikzpicture}
				[level distance=1.5cm]
				\node[state] {+}
				child {
			  		node[state] {+}
			  		child { node[state] {\textbf{1}} }
			  		child {
			  			node[state] {*}
			  			child { node[state] {\textbf{2}} }
		  				child {node[state] {\textbf{3}} }
			  		}
		  		}
		  		child {
		  			node[state] {\textbf{4}}
		  		};
			\end{tikzpicture}
			\end{center}

		\subsection{Eliminacja rekurencji lewej}

			Projektując gramatykę, należy wziąć pod uwagę problem rekurencji lewej (Left recursion).
			Są produkcje gramatyczne, nie pozwalające kodu, które je implementuje przejść do następnego
			terminalu, stosując tą samą produkcję, co prowadzi do rekurencji nieskończonej.
			\\
			
			Rekuręcja lewa może wyglądać następująco:

		    \begin{grammar}
		    	<factor> ::= <factor> '+' <term>
			\end{grammar}

			\spacing

			Kod, wykonujący tą regułe będzie miał postać:
			
			\spacing

			\begin{lstlisting}[label={lst:left-recursion}]
void factor() {
	factor(); // Rekurencja bez zadnego warunku wyjscia
	consume('+');
	term();
}
			\end{lstlisting}
		
		\subsection{Niejednoznaczność}
		
			Projektując język, łatwo trafić na niejednoznaczne produkcje gramatyczne. One są takie, że
			jednego tekstu wejściowego są one w stanie wyprodukować kilka różnych od siebie drzew. Popularny
			warunek dla stworzenia niejednoznaczności to taka produkcja
			
			\begin{grammar}
		        <P> ::= <P> + <P>
				\alt <symbol>
			\end{grammar}
			
			
			Po zastosowaniu danej produkcji dla \texttt{A + B + C} możliwe jest otrzymanie dwóch drzew
			
			\spacing
			\spacing

			\begin{center}
				\begin{tabular}{ L{5cm} L{5cm} }
					\begin{tikzpicture}
						[level distance=1.5cm]
						\node[state] {+}
						child {
					  		node[state] {+}
					  		child { node[state] {\textbf{A}} }
					  		child { node[state] {\textbf{B}} }
				  		}
				  		child {
				  			node[state] {\textbf{C}}
				  		};
					\end{tikzpicture}
					&
					\begin{tikzpicture}
						[level distance=1.5cm]
						\node[state] {+}
						child {
				  			node[state] {\textbf{A}}
				  		}
				  		child {
					  		node[state] {+}
					  		child { node[state] {\textbf{B}} }
					  		child { node[state] {\textbf{C}} }
				  		};
					\end{tikzpicture}
				\end{tabular}
			\end{center}
			
			Aby rozwiązać ten problem i jednoznacznie wskazać kolejność zastosowania reguł gramatycznych,
			możemy zamienić prawy operand na symbol, wtedy eliminuje się dwuznaczność. Pierwsza produkcja
			poniżej jest \textbf{lewostronną}, a druga -- \textbf{prawostronną}.

			\begin{grammar}
		        <P> ::= <P> + <symbol>
	
		        <P> ::= <symbol> + <P>
			\end{grammar}

		\subsection{Implementacja AST}

			Zaimplementowany AST składa się ze struktury \texttt{ast_node}. Jest to główny typ
			węzła, zawierający niektóre zbędne informacje dla każdego typu węzła AST, i przechowujący
			konkretny węzęł jako wskaźnik.

			\spacing

			\begin{lstlisting}[label={lst:ast-node}]
struct ast_node {
    enum ast_type  type;    /* Rozrozniamy typ wedlug tej flagi */
    void          *ast;     /* ast_num, ast_for, ast_while, et cetera */
    uint16_t       line_no;
    uint16_t       col_no;
};
			\end{lstlisting}
			
			\spacing
			
			Konkretne węzły definiujemy w następujący sposób:

			\spacing

			\begin{lstlisting}[label={lst:ast-concrete-node}]
struct ast_num {
    int32_t value;
};
			\end{lstlisting}
			
			\spacing
			
			Taki AST stanowi strukturę drzewiastą, mającą wszystkie zalety i wady drzew jako struktur
			danych. Mając takie drzewo, jesteśmy w stanie prowadzić zwykłe przeszukiwanie w głąb
			i wszerz. W danym przypadku taki algorytm się nazywa \textbf{AST visitor}. Dokładnie w ten
			sposób działa każda z przedstawionych niżej analiz semantycznych
			oraz generacja kodu pośredniego.

			\spacing

			\begin{algorithm}
				\caption{Przeszukiwanie AST}
				\begin{algorithmic}[1]

				\Procedure{DFS}{AST}
					\For{each child node Child of AST}
						\State DFS(Child)
					\EndFor
				\EndProcedure

				\end{algorithmic}
			\end{algorithm}

		\subsection{Implementacja analizatora składniowego}
			
			W danym przypadku, analizator składniowy jest napisany ręcznie, chociaż są narzędzia od
			projektu GNU, takie jak GNU Bison i UNIX'owe, takie jak YACC. Niniejszy analizator
		  	jest napisany bez pomocy tych programów, aby jawnie pokazać, jak się przekładają
		  	produkcje BNF na język C.
		  	\\
		  	
		  	Aby poradzić sobie z zadaniem pisania takiego analizatora, możemy zauważyć, że
		  	zadanie to sprowadza się do implementacji każdej produkcji gramatycznej osobno.
	  	
	  	\subsection{Reprezentacja wizualna AST}
	  		
	  		Jest pokazana też implementacja \textbf{visitor}'u, pozwalającego na przeprowadzenie AST
			do formy tekstowej. Do tego służy funkcja \textbf{ast_dump()}. Przyjmuje ona wskaźnik do
			węzła drewa i działa według algorytmu DFS, opisanego wyżej, przy tym pisząc tekstową formę
			węzłów do pliku (ewentualnie, do \texttt{stdout}). Funkcjonalność ta jest bardzo ważna do
			prowadzenia testów jednostkowych samego AST oraz analizatoru składniowego.
			Niżej pokazany jest przykładowy wynik działania tej funkcji.
			\\
	
			\begin{lstlisting}[label={lst:ast-text}]
CompoundStmt <line:0, col:0>
  StructDecl <line:9, col:1> `custom`
    CompoundStmt <line:9, col:1>
      VarDecl <line:10, col:5> int `a`
      VarDecl <line:11, col:5> int `b`
      VarDecl <line:12, col:5> int `c`
      ArrayDecl <line:13, col:5> char [1000] `mem`
      VarDecl <line:14, col:5> struct string `description`
			\end{lstlisting}
	
	\section{Analiza semantyczna}

		Aby zapewnić poprawność napisanego kodu, stosuje się wiele rodzajów analiz. Niniejszy kompilator
		dysponuje trzema:
		
		\begin{itemize}
			\item Analiza nieużytych zmiennych, oraz zmiennych, które są zdefiniowane, ale nie zostały użyte
			\item Analiza poprawności typów
			\item Analiza prawidłowego użycia funkcji
		\end{itemize}
		
		\subsection{Analiza nieużywanych zmiennych}
			
			Podamy przykłady kodu prowadzącego do odpowiednich ostrzeżeń
			
			\spacing

			\begin{lstlisting}[label={lst:warn-unused-var}]
void f() {
	int argument = 0; // Warning: unused variable `argument`
}
			\end{lstlisting}

			\begin{lstlisting}[label={lst:warn-unused-var}]
void f(int argument) { // Warning: unused variable `argument`

}
			\end{lstlisting}
			
			\begin{lstlisting}[label={lst:warn-unused-var}]
void f() {
	int argument = 0;
	++argument; // Warning: variable `argument` written, but never read
}
			\end{lstlisting}

			%% (\ref{lst:warn-unused-var})
			
			\spacing
			
			Rzecz polega na przejściu drzewa syntaksycznego i zwiększania liczników
			\textbf{read_uses} i \textbf{write_uses} dla każdego węzła typu
			\textbf{ast_sym}.
			\\
			
			Algorytm operuje na blokach kodu, zawartego w \textbf{\{ ... \}}. Po przejściu każdego bloku
			(w tym rekurencyjnie), analiza jest wykonana w następujący sposób:

			\begin{algorithm}
				\caption{Wyszukiwanie nieużywanych zmiennych}
				\begin{algorithmic}[1]

				\Procedure{Analyze}{AST}
					\State Set $\gets$ all declarations at current scope depth

					\For{each collected declaration Use in Set}
						\If{Use is not a function \& Use.ReadUses is 0}
							\State Emit warning
						\EndIf
					\EndFor
				\EndProcedure

				\end{algorithmic}
			\end{algorithm}

			Do analizy nieużywanych funkcji stosuje się tem sam algorytm. Jedyne, co jest wtedy zmienione --
			sprawdzenie, czy nazwa rozpatrywanej funkcji nie jest \textbf{main}. Funkcja \textbf{main} jest
			wywołana automatycznie.
		
		\section{System typów}
		
			\subsection{Opis}

				Wiele zasad, dotyczących pracy z typami mogą być precyzyjnie opisane zasadami typów
				(\textbf{Typing rules}). Jest to notacja matematyczna, stworzona przez \textbf{Per Martin-Löf}'a,
				szwedzkiego matematyka.
				\\

				Kluczowym pojęciem w tej notacji jest \textbf{statyczne środowisko typów}
				(\textbf{static typing environment}). Oznacza się ono symbolem $\Gamma$. Mówimy, że to
				środowisko jest skonstruowane poprawnie pisząc $$\Gamma \vdash \diamond$$
				
				Mówimy, że zmienna \textbf{V} ma typ \textbf{T} w środowisku $\Gamma$ pisząc
				$$\Gamma \vdash \text{V} : T$$
				
				Kreska pozioma mówi o tym, że zdanie wyżej jest konieczne, aby zaszło zdanie niżej

				\begin{mathpar}
				\inferrule
				  {\Gamma \vdash \diamond}
				  {\Gamma \vdash \text{V} : T}
				\end{mathpar}
				
				Zauważmy, że notacja ta jest mocnyn narzędziem, pozwalającym opisać dość złożone systemy typów
				dla takich języków jak \textbf{C++} i \textbf{Haskell}.

			\subsection{Definicja systemu}

				Opiszmy teraz system typów w naszym języku

				\begin{mathpar}
				\inferrule
				  {\Gamma \vdash \diamond}
				  {\Gamma \vdash \text{true} : bool}
				\quad

				\inferrule
				  {\Gamma \vdash \diamond}
				  {\Gamma \vdash \text{false} : bool}
				\end{mathpar}

				\begin{mathpar}
				\inferrule
				  {\Gamma \vdash \diamond}
				  {\Gamma \vdash \text{n} : int}

				\inferrule
				  {\Gamma \vdash \diamond}
				  {\Gamma \vdash \text{c} : char}

				\inferrule
				  {\Gamma \vdash \diamond}
				  {\Gamma \vdash \text{x} : float}
				\end{mathpar}

			Oznaczmy dla $\mathbb{N, R}: \oplus \in \{ =, +, -, *, /, <, >, \le, \ge, ==, \neq, ||, \&\& \}$, wtedy

				\begin{mathpar}
				\inferrule
				  {\Gamma \vdash e_l : float \\ \Gamma \vdash e_r : float}
				  {\Gamma \vdash e_l \oplus e_r : float}
				\end{mathpar}

				\spacing

			Dodamy do $\oplus$ operacje tylko dla $\mathbb{N}: \oplus \ \cup \ \{ |, \&, \string^, <<, >>, \% \}$, wtedy

				\spacing

				\begin{mathpar}
				\inferrule
				  {\Gamma \vdash e_l : int \\ \Gamma \vdash e_r : int}
				  {\Gamma \vdash e_l \oplus e_r : int}

				\inferrule
				  {\Gamma \vdash e_l : int \\ \Gamma \vdash e_r : char}
				  {\Gamma \vdash e_l \oplus e_r : char}
				\end{mathpar}

				\spacing

				Wprowadźmy reguły niejawnej konwersji, które są niezbędne przy sprawdzaniu w warunku
				logicznym wyniku operacji arytmetycznej, zwracającej typ różny od
				\texttt{bool}. Oznaczmy reguły dla typów \texttt{int}, \texttt{char} i \texttt{float}.
				
				\begin{mathpar}
				\inferrule
					{\Gamma \vdash \text{e} : int}
					{\Gamma \vdash \text{e} : bool}

				\inferrule
					{\Gamma \vdash \text{e} : char}
					{\Gamma \vdash \text{e} : bool}

				\inferrule
					{\Gamma \vdash \text{e} : float}
					{\Gamma \vdash \text{e} : bool}
				\end{mathpar}

				\spacing
				
				Wprowadźmy także reguły do operacji wskaźnikowych. Oznaczmy
				$\oplus \in \{ +, - \}$ i $\tau$ jako wskaźnik dowolnego typu, wtedy

				\begin{mathpar}
				\inferrule
					{\Gamma \vdash e_l : \tau \ * \\ \Gamma \vdash e_r : \tau \ *}
					{\Gamma \vdash e_l \oplus e_r : \tau \ *}

				\inferrule
					{\Gamma \vdash e_l : \tau \ * \\ \Gamma \vdash e_r : int}
					{\Gamma \vdash e_l \oplus e_r : \tau \ *}

				\inferrule
					{\Gamma \vdash e_l : int \\ \Gamma \vdash e_r : \tau \ *}
					{\Gamma \vdash e_l \oplus e_r : \tau \ *}
				\end{mathpar}

				Dla $\oplus \in \{ ==, !=, <, >, \le, \ge \}$

				\begin{mathpar}
				\inferrule
					{\Gamma \vdash e_l : \tau \ * \\ \Gamma \vdash e_r : \tau \ *}
					{\Gamma \vdash e_l \oplus e_r : int}
				\end{mathpar}

				Mając taką konwersję, możemy wprowadzić reguły do konstrukcji warunkowych: 

				\begin{mathpar}
				\inferrule
				  {\Gamma \vdash \text{condition} : bool \\ \Gamma \vdash e_1 : \tau \\ \Gamma \vdash e_2 : \tau}
				  {\Gamma \vdash \text{if (condition) } \{ \ e_1 \ \}  \text{ else }  \{ \ e_2 \ \} : \tau}

				\inferrule
					{\Gamma \vdash \text{condition} : bool \\ \Gamma \vdash e : \tau}
					{\Gamma \vdash \text{while (condition) } \{ \ e \ \} : \tau}

				\inferrule
					{\Gamma \vdash \text{condition} : bool \\ \Gamma \vdash e : \tau}
					{\Gamma \vdash \text{do } \{ \ e \ \} \text{ while (condition)} : \tau}

				\inferrule
					{\Gamma \vdash \text{init} : \tau_1 \\
					 \Gamma \vdash \text{condition} : bool \\
					 \Gamma \vdash \text{increment} : \tau_2 \\ \Gamma \vdash e : \tau_3}
					{\Gamma \vdash \text{for (init; condition; increment) } \{ \ e \ \} : \tau_3}
				\end{mathpar}

	\section{Generacja kodu pośredniego}
		
		Kod pośredni -- jest to język, składający się z elementarnych operacji nad danymi, takimi jak
		arytmetyczne operacje, zapisanie do komórki pamięci.
		\\
		
		Im prostszy ten język jest, tym prostsze
		są algorytmy do analizy, optymalizacji i generacji dalszych warstw pośrednich.
		\\
		
		Istnieje wiele różnych podobnych do assemblera języków (Intermediate representation, \textbf{IR}), służącego
		do generacji kodu maszynowego (LLVM IR, GIMPLE, FIRM). Jednak, niniejszy język implementuje własny IR z
		kilku powodów:
		
		\begin{itemize}
			\item Jest prostszy
			\item Ma prostszy interfejs programistyczny
			\item Nie stanowi dodatkowych zależności jako biblioteki
			\item Ma na celu pokazanie metod na tworzenie takiego języka i operacje nad nimi
		\end{itemize}
		
		\subsection{Algorytm}
			Generator IR przyjmuje AST jako wejście. Stworzenie instrukcji pośrednich
			polega na rekurencyjnym przejściu tego drzewa oraz tłumaczeniu danych o
			programie z poziomu drzewa (w zasadzie elementów syntaksycznych) na język
			niskiego poziomu. W zależności od węzła musi być stworzony kod, zachowujący
			się zgodnie z oczekiwaniem użytkownika.
			\\
			
			Naprzykład, pętla while (po lewej stronie) zostanie przetłumaczona na
			kod niskiego poziomu (po prawej stronie).

			\begin{center}
			\begin{tabular}{ c c c }
			\begin{lstlisting}[label={lst:warn-unused-var},linewidth=6.5cm]
int main() {
    int i = 1;
    while (i < 10 && i != 0)
    {
        int j = i;
        ++j;
        ++i;
    }
    return 0;
}			
.
.
.
.
.
.
.
			\end{lstlisting}
			& &	
			\begin{lstlisting}[label={lst:warn-unused-var},linewidth=8cm]
fun main():
       0:   int t0
       1:   t0 = 1
       2:   | int t1
       3:   | int t2
       4:   | t2 = t0 < 10
       5:   | int t3
       6:   | t3 = t0 != 0
       7:   | t1 = t2 && t3
       8:   | if t1 != 0 goto L10
       9:   | jmp L15
      10:   | int t4
      11:   | t4 = t0
      12:   | t4 = t4 + 1
      13:   | t0 = t0 + 1
      14:   | jmp L2
      15:   ret 0
			\end{lstlisting}
			\end{tabular}
			\end{center}
			
			Widać, że złożona semantycznie konstrukcja \texttt{while} została
			przedstawiona za pomocą prostszych do wykonania operacji: stworzyć
			zmienną o rozmiarze N bajtów, zapisać do niej wynik operacji binarnej,
			wykonać skok do instrukcji o pewnym indeksie. Analogicznie przedstawione są
			inne części języka (\texttt{for}, \texttt{do while}, \texttt{if}). Oczywiście,
			wszystkie konstrukcje mogą być zagnieżdżone dowolną ilośc razy, przy tym
			zachowawszy liniową strukturę IR.

		\subsection{Instrukcje}

		Zdefiniowane w implementacji struktury dzielą się
		na instrukcje i typy danych.

		\begin{center}
			\setlength{\tabcolsep}{0.5em}
			\renewcommand{\arraystretch}{1.5}
			\definecolor{instrc}{gray}{0.4}
			\begin{tabular}{| L{0.2\linewidth} | L{0.75\linewidth} | }
				\hline
				\textbf{Instrukcja} & \textbf{Opis} \\
				\hline
				\textcolor{instrc}{\textbf{ir\_alloca}}
					& Alokacja określonej ilości bajtów
                     na stosie. \\
				\hline
				\textcolor{instrc}{\textbf{ir\_alloca\_array}}
                	& Alokacja określonej ilości bajtów
					  na stosie, pomnożonej przez rozmiar
                      tablicy. \\
				\hline
				\textcolor{instrc}{\textbf{ir\_store}} 
					& Zapisanie wartości do zmiennej
                      lub do tablicy o wskazanym
                      indeksie. \\
				\hline

				\textcolor{instrc}{\textbf{ir\_jump}}
					& Przekazanie przepływu sterowania
                      do instrukcji o wskazanym indeksie. \\
				\hline
				\textcolor{instrc}{\textbf{ir\_cond}}
					& Instrukcja warunkowa. Wykonuje skok
             	     (taki sam, jak \texttt{ir\_jump}),
                      jeżeli warunek jest spełniony.
                      Inaczej sterowanie się przekazuje
                      do następnej instrukcji. \\
  				\hline
  				\textcolor{instrc}{\textbf{ir\_ret}}
  					& Wyjście z funkcji. Może mieć lub nie
                      mieć wartość zwracaną. \\
      			\hline
      			\textcolor{instrc}{\textbf{ir\_fn\_call}}
                    & Wywołanie funkcji. \\
                \hline
			\end{tabular}
		\end{center}
		
		\spacing

		\begin{center}
			\setlength{\tabcolsep}{0.5em}
			\renewcommand{\arraystretch}{1.5}
			\definecolor{instrc}{gray}{0.4}
			\begin{tabular}{| L{0.2\linewidth} | L{0.75\linewidth} | }
				\hline
				\textbf{Typ} & \textbf{Opis} \\
				\hline
				\textcolor{instrc}{\textbf{ir\_imm}}
					& Wartość (int, char, bool). \\
                \hline
				\textcolor{instrc}{\textbf{ir\_string}}
					& Łańcuch znaków. \\
				\hline
				\textcolor{instrc}{\textbf{ir\_sym}}
					& Indeks zmiennej. \\
				\hline
				\textcolor{instrc}{\textbf{ir\_bin}}
					& Operacja binarna (dwuargumentowa). \\
				\hline
				\textcolor{instrc}{\textbf{ir\_member}}
					& Operacja dostępu do indeksu tablicy. \\
				\hline
				\textcolor{instrc}{\textbf{ir\_type\_decl}}
					& Definicja typu. \\
				\hline
				\textcolor{instrc}{\textbf{ir\_fn\_decl}}
					& Definicja funkcji. \\
				\hline
			\end{tabular}
		\end{center}

		\subsection{Generacja grafu sterowania}

		\tikzstyle{process} = [rectangle, minimum width=3cm, minimum height=0.5cm,text centered, draw=black]
		\tikzstyle{arrow} = [thick,->,>=stealth]

		\begin{center}
			\begin{tabularx}{\textwidth}{ L{9cm} L{9cm} }

			\begin{tikzpicture}[node distance=1cm]
				\node (0) [process] {$int \ t_0$};
				\node (1) [process, below of=0] {$t_0 = 1$};
				\node (2) [process, below of=1] {$int \ t_1$};
				\node (3) [process, below of=2] {$int \ t_2$};
				\node (4) [process, below of=3] {$t_2 = t_0 < 10$};
				\node (5) [process, below of=4] {$int \ t_3$};
				\node (6) [process, below of=5] {$t_3 \ = \ t_0 != 0$};
				\node (7) [process, below of=6] {$t_1 \ = \ t_2 \ \&\& \ t_3$};
				\node (8) [process, below of=7] {$if \ t_1 \ != \ 0 \ goto \ L10$};
				\node (9) [process, below of=8, right of=8, xshift=1cm] {$jmp \ L15$};
				\node (10) [process, below of=8, xshift=-1.5cm] {$int \ t4$};
				\node (11) [process, below of=10] {$t_4 \ = \ t_0$};
				\node (12) [process, below of=11] {$t_4 \ = \ t_4 \ + \ 1$};
				\node (13) [process, below of=12] {$t_0 \ = \ t_0 \ + \ 1$};
				\node (14) [process, below of=13] {$jmp \ L2$};
				\node (15) [process, below of=14, xshift=1.5cm] {$ret \ 0$};

				\draw [arrow] (0) -- (1);
				\draw [arrow] (1) -- (2);
				\draw [arrow] (2) -- (3);
				\draw [arrow] (3) -- (4);
				\draw [arrow] (4) -- (5);
				\draw [arrow] (5) -- (6);
				\draw [arrow] (6) -- (7);
				\draw [arrow] (7) -- (8);
				\draw [arrow] (8) -- (9);
				\draw [arrow] (8) -- (10);
				\draw [arrow, bend left=45] (9.south) to (15.east);
				\draw [arrow] (10) -- (11);
				\draw [arrow] (11) -- (12);
				\draw [arrow] (12) -- (13);
				\draw [arrow] (13) -- (14);
				\draw [arrow, bend left=30] (14.west) to (2.west);
			\end{tikzpicture}
		&
		Wygenerowana poprzednio warstwa poprzednia zawiera wszystkie informacje, dotyczące operacji nad
		danymi, ale brakuje jeszcze informacji o przepływie sterowania. Aby wiedzieć, która instrukcja się
		wykonuje po której, musimy stworzyć związek między poprzednią i następną instrukcją, który określa się
		następująco
		
		\begin{itemize}
			\item Instrukcja warunkowa ma dwóch następników. Jeden jest wykonany w przypadku spełnionengo warunku,
			      a drugi -- gdy warunek nie zaszedł.
			\item Instrukcja skokowa ma jednego następnika, niekoniecznie będącego następnikiem na liście kodu.
				  Jeżeli index instrukcji docelowej jest $<$ od instrukcji skoku, powstaje \textbf{krawędź powrotna}
				  (\textbf{back edge}). Wszystkie inne krawędzi są \textbf{skierowane w przód} (\textbf{forward edge}).
		\end{itemize}
	
		W przykładzie, pokazanym po lewej stronie, jest jedna krawędź powrotna, wiodąca od $jmp \ L2$ do
		$int \ t_1$.
		$$$$ % \\ spacing breaks table alignment. This not.
		Otrzymany graf jest użyteczny przy wielu rodzajach optymalizacji. Naprzykład, przy usuwaniu kodu nieosiądalnego
		oraz analizie zależności danych.

		\end{tabularx}
		\end{center}

	\section{Optymalizacje (teoria)}
		
		Optymalizacja -- to zmiana kodu programu, mająca na celu polepszyć wydajność albo inne cechy
		programu. Najważniejym z kriteria optymalizacji jest utrzymanie całej struktury działania programu,
		takiej, jak chce programista. Nie wolno przeprowadzać wiodące do niespodziewanych lub
		niepoprawnych wyników optymalizacje.
		\\
		
		Istnieje wiele rodzajów optymalizacji, gdzie każda wymaga więcej lub mniej założeń i
		matematyki. Jeżeli chodzi o matematykę, to główną rolę w optymalizacji pełni \textbf{teoria grafów}.
		Jednym z pierwszych naukowców, kto zadecydował wprowadzić modele grafowe do kompilatorów był
		\textbf{Robert Tarjan}. Wprowadził także on algorytm do obliczenia drzewa dominatorów (dominator tree).

		\subsection{Definicje}
			Każdy program posiadą taką cechę jak \textbf{przepływ sterowania}, i może ona być
			precyzyjnie wyrażona \textbf{grafem przepływu sterowania} (Control Flow Graph). Program
			rozpatrywany jest jako graf skierowany, posiadający wierzchołek startowy, będący pierwszą
			instrukcją w programie. Krawędzie reprezentują przejścia pomiędzy instrukcjami. Zauważmy,
			że każda instrukcja może mieć wiele krawędzi wejściowych i wyjściowych, tworząc \textbf{gałęzi}
			w wykonaniu programu.
			\\
			
			Oznaczmy kilka ważnych pojęć.
			\\

			Niech $G = (V, E, s)$ -- graf skierowany.
			$V$ -- zbiór wierzchołków. $E$ -- zbiór krawędzi. $s$ -- węzęł początkowy.
			$G' = (V', E') \subseteq G$ -- podgraf, gdzie każdy wierzchołek $v \in G'$ jest nieosiągalny z
			dowolnej ścieżki $(s, ...,  v) \in G$. Zauważmy, że $G'$ może być grafem rozłącznym.

			$$V' = \{ \ v \ | \ \forall \ v \ \nexists \ (s, ..., v) \ \}$$

			\spacing

			Niech $G = (V, E, s)$ -- graf skierowany, zdefiniowany powyżej. Graf zależności danych -- graf
			$G' = (V', E', D')$. Wtedy $D' = \{ \ d, d' \in V' \ | \ d \rightarrow d' \ \}$. Przez $d \rightarrow d'$
			oznaczona zależnośc $d$ od wyniku obliczenia $d'$. Zbiór $D'$ reprezentuje takie zależności, przy czym
			dodatkowo musi być spełnione

			$$d, d' \in V', \ v \rightarrow v' \iff \exists \ (v', ..., v) \in G' $$

			\subsection{SSA}
				Static Assignment Form (SSA) -- ważna forma reprezentacji programu. Nazywa się
				tak program, w którym każda zmienna jest zapisana dokładnie jeden raz. Odkrywa
				to wiele możliwości do prowadzenia optymalizacji, na przykład jest to propagacja
				 zmiennych stałych i alokacja rejestrów.

				Konstrukcja SSA składa się z kilku etapów:
				\begin{itemize}
					\item Obliczenie drzewa dominatorów (dominator tree).
					\item Obliczenie granicy dominacji (dominance frontier).
					\item Wstawianie $\phi$-funkcji (zob. niżej).
				\end{itemize}
				Istnieje przynajmniej dwa algorytmy do obliczenia SSA na różne sposoby. Pierwszy
				autorstwa \textbf{Ron Cytron} i kilku innych matematyków (An Efficient
				Method of Computing Static Single Assignment Form). Drugi autorstwa
				\textbf{Quan Hoang Nguyen} (Computing SSA Form with Matrices). Został
				zaimplementowany pierwszy algorytm, skoro jest prostrzy i wymaga mniej (chociaż
				też dużo) kultury matematycznej. Nie będziemy udowadniać tutaj całego algorytmu,
				pokażemy tylko główne jego idee.
				
				\subsection{SSA: drzewo dominatorów}
					Do obliczenia drzewa dominatorów używa się algorytm, stworzony przez dwóch
					matematyków -- algorytm \textbf{Lengauer-Tarjan}'u. Jest on profesjonalnie
					zbudowany i udowodniony matematycznie. Składa się on z trzech części
					\begin{enumerate}
						\item Przejście grafu w głąb (zwykły DFS).
						\item Przejście wyniku DFS w odwrotnej kolejności, zatem przeliczanie
						      półdominatorów (\textbf{semidominators}).
				      	\item Za pomocą półdominatorów definicja dominatorów.
					\end{enumerate}

				\subsection{SSA: granica dominacji}
				
				\subsection{SSA: $\phi$-funkcje}
					
	\section{Optymalizacje (implementacja)}
		\subsection{Unreachable code elimination}
		
			Usuwanie kodu nieosiągalnego polega na dwóćh krokach.
			\begin{itemize}
				\item Obejście grafu sterowania programu (\textbf{CFG})
				\item Usuwanie wszystkich instrukcji, do których nie ma żadnych wejściowych krawędzi.
			\end{itemize}
			
			\spacing

			Algorytm polega na zlalezieniu takich \textbf{podgrafów} grafu sterowania programem, do których
			nie prowadzi żadna z krawędzi.

			\begin{algorithm}
				\caption{Usuwanie kodu nieosiągalnego}
				\begin{algorithmic}[1]
					\Procedure{Eliminate}{CFG}
						\State Visited $\gets$ $\emptyset$
						\State \Call{Traverse}{Visited, CFG, First(CFG)}
						\State Unvisited $\gets$ CFG $\setminus$ Visited
						\State \Call{Cut}{Unvisited, CFG}
					\EndProcedure
					\\
					\Procedure{Traverse}{Visited, CFG, IR}
						\State Visited[IR] $\gets$ 1
						\For{each control flow successor of IR}
							\State \Call{Traverse}{Visited, CFG, Succ(IR)}
						\EndFor
					\EndProcedure
					\\
					\Procedure{Cut}{Unvisited, CFG}
						\For{each unvisited statement}
							\State Remove statement from IR
						\EndFor
					\EndProcedure
				\end{algorithmic}
			\end{algorithm}

		\newpage

	\section{Interpreter}

		\begin{center}
			\begin{tabularx}{\textwidth}{ L{9cm} L{9cm} }
				% https://tex.stackexchange.com/questions/235000/drawing-an-activation-stack-in-latex
				% https://lpn-doc-sphinx-primer.readthedocs.io/en/latest/extensions/tikz/tikzgoodies.html
				\begin{tikzpicture}[x=1.05cm,y=0.7cm]
					\small

					\cell[draw=none]{Stos}
					\cell[fill=white]{\texttt{call main()}}     \cellcomL{global=0}          \coordinate (p0)    at (currentcell.east);
					\cell[fill=white]{\texttt{int a = 0}}       \cellcomL{global=4}          \coordinate (p4)    at (currentcell.east);
					\cell[fill=white]{\texttt{int b = 0}}       \cellcomL{global=8}          \coordinate (p8n1)  at (currentcell.east);
					\cell[fill=white]{\texttt{call f()}}        \cellcomL{global=8}          \coordinate (p8n2)  at (currentcell.east);
					\cell[fill=white]{\texttt{int c = 0}}       \cellcomL{global=12,local=4} \coordinate (p12)   at (currentcell.east);
					\cell[fill=white]{\texttt{int d = 0}}       \cellcomL{global=16,local=8} \coordinate (p16n1) at (currentcell.east);
					\cell[fill=white]{\texttt{return from f()}} \cellcomL{global=8}          \coordinate (p16n2) at (currentcell.east);
					\cell[fill=white]{\texttt{return b}}        \cellcomL{global=8}          \coordinate (p16n3) at (currentcell.east);
					\stackbottom[fill=white]{}

					% todo: Draw from borders.
					\draw[->] (p16n3) to [bend right=100] (p8n1);
				\end{tikzpicture}
				&
				Interpreter -- program, który produkuje dane wyjściowe zgodnie z zasadami semantycznymi, które
				są opisane językiem. W naszym przypadku, interpreter przetwarza wygenerowany poprzednio IR.
				$$$$
				Niniejszy interpreter działa używając stosu. Jest to struktura danych, pozwalająca dodawać i 
				usuwać dane tylko z górnej części stosu. Określamy operacje \textbf{push} i \textbf{pop}.
				Stos, używany przez interpreter jednak wspiera przegląd wartości o dowolnej pozycji w stosie.
			\end{tabularx}
		\end{center}
		
		Aby zarządzać pamięcią podczas wykonania, musimy zdecydować, na jaki sposób zaimplementować
		\textbf{adresację} zmiennych. Jest to operacja, która utożsamia nazwę zmiennej z jej adresem w pamięci.
		Istineije dwie możliości
		\\
		
		\textbf{Statyczna alokacja pamięci} -- sposób adresacji, przy którym adres każdej zmiennej określony
		jednoznacznie. Jest użyteczna do początkowych wersji ALGOL i COBOL, które nie wspierają rekurencyjne
		wywołania funckji.
		\\
		
		\textbf{Dynamiczna alokacja pamięci} -- spobób adresacji, przy którym niemożliwe jest obliczenie
		fizycznego adresu zmienneij, skoro stworzona ona może być w funkcji, wywołanej przez inną funkcję
		bądź samą siebie. Naprzykład, dana funkcja \textbf{f()}, która definiuje zmienną \textbf{i}, i
		załóżmy, że wywoła ona się rekurencyjnie. Wtedy podczas pierwszego wywołania zmienna \textbf{i}
		będzie miała adres \textbf{0x00}. Podczas drugiego wywołania \textbf{0x04}, dalej \textbf{0x08},
		\textbf{0x0C}, ...

		\newpage

	\section{Annex: Gramatyka w BNF}

        \setlength{\grammarindent}{12em}

        \begin{grammar}
            <program> ::= ( <function-decl> | <structure-decl> )*

            <structure-decl> ::= \tt{struct} \tt{\{} <structure-decl-list> \tt{\}}

            <structure-decl-list> ::= (
            <decl-without-initialiser> \tt{;}
            \alt <structure-decl> \tt{;}
            )*

            <function-decl> ::= <ret-type> <id> \tt{(} <parameter-list-opt> \tt{)} \tt{\{} <stmt>* \tt{\}}

            <ret-type> ::= <type>
            \alt <void-type>

            <type> ::= \tt{int}
            \alt \tt{float}
            \alt \tt{char}
            \alt \tt{string}
            \alt \tt{boolean}

            <void-type> ::= \tt{void}

            <constant> ::= <integral-literal>
            \alt <floating-literal>
            \alt <string-literal>
            \alt <char-literal>
            \alt <boolean-literal>

            <integral-literal> ::= <digit>*
            
            <floating-literal> ::= <digit>* \tt{.} <digit>*

            <string-literal> ::= ''\tt{( "x00000000-x0010FFFF" )*}''

            <char-literal> ::= '\tt{ASCII(0)}-\tt{ASCII(127)}'

            <boolean-literal> ::= \tt{true}
            \alt \tt{false}

            <alpha> ::= \tt{a} | \tt{b} | ... | \tt{z} | \tt{_}

            <digit> ::= \tt{0} | \tt{1} | ... | \tt{9}

            <id> ::= <alpha> ( <alpha> | <digit> )*

            <array-decl> ::= <type> ( \tt{*} )* <id> \tt{[} <integral-literal> \tt{]}

            <var-decl> ::= <type> ( \tt{*} )* <id> \tt{=} <logical-or-stmt> \tt{;}
            
            <structure-var-decl> ::= <id> ( \tt{*} )* <id>

            <decl> ::= <var-decl>
            \alt <array-decl>
            \alt <structure-var-decl>

            <decl-without-initialiser> ::= <type> ( \tt{*} )* <id>
            \alt <array-decl>
            \alt <structure-var-decl>

            <parameter-list> ::= <decl-without-initialiser> \tt{,} <parameter-list>
            \alt <decl-without-initialiser>

            <parameter-list-opt> ::= <parameter-list> | $\epsilon$

            <stmt> ::= <block-stmt>
            \alt <selection-stmt>
            \alt <iteration-stmt>
            \alt <jump-stmt>
            \alt <decl>
            \alt <expr>
            \alt <assignment-stmt>
            \alt <primary-stmt>
            
            <member-access-stmt> ::= <id> \tt{.} <member-access-stmt>
            \alt <id> \tt{.} <id>

            <iteration-stmt> ::= <stmt>
            \alt \tt{break};
            \alt \tt{continue};
            
            <block-stmt> ::= \tt{\{} <stmt>* \tt{\}}
            
            <iteration-block-stmt> ::= \tt{\{} <iteration-stmt>* \tt{\}}

            <selection-stmt> ::= \tt{if} \tt{(} <expr> \tt{)} <block-stmt>
            \alt \tt{if} \tt{(} <expr> \tt{)} <block-stmt> \tt{else} <block-stmt>

            <iteration-stmt> ::= \tt{for} \tt{(} <expr-opt> \tt{;} <expr-opt> \tt{;} <expr-opt> \tt{)} <iteration-block-stmt>
            \alt \tt{for} \tt{(} <decl> \tt{:} <symbol-stmt> \tt{)} <iteration-block-stmt>
            \alt \tt{while} \tt{(} <expr> \tt{)} <iteration-block-stmt>
            \alt \tt{do} <iteration-block-stmt> \tt{while} \tt{(} <expr> \tt{)} \tt{;}

            <jump-stmt> ::= \tt{return} <expr> ? \tt{;}

            <assignment-op> ::= \tt{=}
            \alt \tt{*=}
            \alt \tt{/=}
            \alt \tt{\%=}
            \alt \tt{+=}
            \alt \tt{-=}
            \alt \tt{"<<="}
            \alt \tt{">>="}
            \alt \tt{\&=}
            \alt \tt{|=}
            \alt \tt{"^="}

            <expr> ::= <assignment-stmt>
            \alt <var-decl>

            <expr-opt> ::= <expr> | $\epsilon$

            <assignment-stmt> ::= <logical-or-stmt>
            \alt <logical-or-stmt> <assignment-op> <assignment-stmt>

            <logical-or-stmt> ::= <logical-and-stmt>
            \alt <logical-and-stmt> \tt{||} <logical-or-stmt>

            <logical-and-stmt> ::= <inclusive-or-stmt>
            \alt <inclusive-or-stmt> \tt{\&\&} <logical-and-stmt>

            <inclusive-or-stmt> ::= <exclusive-or-stmt>
            \alt <exclusive-or-stmt> \tt{|} <inclusive-or-stmt>

            <exclusive-or-stmt> ::= <and-stmt>
            \alt <and-stmt> \tt{"^"} <exclusive-or-stmt>

            <and-stmt> ::= <equality-stmt>
            \alt <equality-stmt> \tt{\&} <and-stmt>

            <equality-stmt> ::= <relational-stmt>
            \alt <relational-stmt> \tt{==} <equality-stmt>
            \alt <relational-stmt> \tt{!=} <equality-stmt>

            <relational-stmt> ::= <shift-stmt>
            \alt <shift-stmt> \tt{">"} <relational-stmt>
            \alt <shift-stmt> \tt{"<"} <relational-stmt>
            \alt <shift-stmt> \tt{">="} <relational-stmt>
            \alt <shift-stmt> \tt{"<="} <relational-stmt>

            <shift-stmt> ::= <additive-stmt>
            \alt <additive-stmt> \tt{"<<"} <shift-stmt>
            \alt <additive-stmt> \tt{">>"} <shift-stmt>

            <additive-stmt> ::= <multiplicative-stmt>
            \alt <multiplicative-stmt> \tt{"+"} <additive-stmt>
            \alt <multiplicative-stmt> \tt{"-"} <additive-stmt>

            <multiplicative-stmt> ::= <prefix-unary-stmt>
            \alt <prefix-unary-stmt> \tt{"*"} <multiplicative-stmt>
            \alt <prefix-unary-stmt> \tt{"/"} <multiplicative-stmt>
            \alt <prefix-unary-stmt> \tt{"%"} <multiplicative-stmt>

            <prefix-unary-stmt> ::= <postfix-unary-stmt>
            \alt \tt{++} <postfix-unary-stmt>
            \alt \tt{--} <postfix-unary-stmt>
            \alt \tt{*} <postfix-unary-stmt>
            \alt \tt{\&} <postfix-unary-stmt>
            \alt \tt{!} <postfix-unary-stmt>

            <postfix-unary-stmt> ::= <primary-stmt>
            \alt <primary-stmt> \tt{++}
            \alt <primary-stmt> \tt{--}

            <primary-stmt> ::= <constant>
            \alt <symbol-stmt>
            \alt \tt{(} <logical-or-stmt> \tt{)}
            
            <symbol-stmt> ::= <function-call-stmt>
            \alt <array-access-stmt>
            \alt <member-access-stmt>
            \alt <id>
            
            <array-access-stmt> ::= <id> ( \tt{[} <expr> ] )*
            
            <function-call-arg-list> ::= <logical-or-stmt> \tt{,} <function-call-arg-list>
            \alt <logical-or-stmt>
            
            <function-call-arg-list-opt> ::= <function-call-arg-list> | $\epsilon$

            <function-call-expr> ::= <id> \tt{(} <function-call-arg-list-opt> \tt{)}

        \end{grammar}

		\newpage

	\begin{thebibliography}{9}
		\bibitem{texbook}
			https://www.bates.edu/biology/files/2010/06/How-to-Write-Guide-v10-2014.pdf
		
		\bibitem{texbook}
			Bauer, Friedrich Ludwig,
			\emph{Compiler construction},
			1974, Berlin,
			ISBN: 3-540-06958-5
		
		\bibitem{texbook}
			http://lucacardelli.name/papers/typesystems.pdf
	
		\bibitem{texbook}
			https://gcc.gnu.org/onlinedocs/gccint/GIMPLE.html

		\bibitem{texbook}
			https://llvm.org/docs/LangRef.html

		\bibitem{texbook}
			https://github.com/libfirm/libfirm
	\end{thebibliography}
	
	\newpage
	
    \tableofcontents

\end{document}