\documentclass[leqno, 12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[polish]{babel}
\usepackage{polski}
\usepackage[fleqn]{amsmath}  % Aligned to left equations.
\usepackage{amssymb}
\usepackage[a4paper, total={7.5in, 9.5in}]{geometry}
\usepackage{indentfirst}
\usepackage{amsfonts}
\usepackage[dvipsnames]{xcolor}

\usepackage{caption}
\usepackage{chngcntr}
\usepackage{cleveref}

\usepackage{geometry}

\usepackage{syntax}
\usepackage{fancyhdr}
\usepackage{mathpartir}

\usepackage{array}
\usepackage{listings}

\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage[autosize]{dot2texi}
\usepackage{tikz}

\usetikzlibrary{automata}
\usetikzlibrary{positioning}
\usetikzlibrary{shapes}
\usetikzlibrary{arrows}
\usetikzlibrary{chains}
\usetikzlibrary{calc}

\algnewcommand\algorithmicswitch{\textbf{switch}}
\algnewcommand\algorithmiccase{\textbf{case}}
\algnewcommand\algorithmicassert{\texttt{assert}}
\algnewcommand\Assert[1]{\State \algorithmicassert(#1)}%
% New "environments"
\algdef{SE}[SWITCH]{Switch}{EndSwitch}[1]{\algorithmicswitch\ #1\ \algorithmicdo}{\algorithmicend\ \algorithmicswitch}%
\algdef{SE}[CASE]{Case}{EndCase}[1]{\algorithmiccase\ #1}{\algorithmicend\ \algorithmiccase}%
\algtext*{EndSwitch}%
\algtext*{EndCase}%

\lstset{
    xleftmargin    = .2\textwidth,
    xrightmargin   = .2\textwidth,
    basicstyle     = \footnotesize\ttfamily,
    breaklines     = true,
    linewidth      = 16cm
}

\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering  \let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft \let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

\newcommand\kk[1]{\textcolor{RoyalBlue}{\text{\textup{\textbf{\texttt{#1}}}}}}
\newcommand\cc[1]{\textcolor{Sepia}{\text{\textup{\textbf{\texttt{#1}}}}}}


\newcommand{\spacing}{\vskip 0.5cm}

\let\titleoriginal\title           % save original \title macro
\renewcommand{\title}[1]{          % substitute for a new \title
    \titleoriginal{#1}%            % define the real title
    \newcommand{\thetitle}{#1}     % define \thetitle
}

\lstset{
	firstnumber = 0,
	tabsize     = 4,
	frame       = none,
	linewidth   = 1.2\textwidth,
	xleftmargin = 0cm
}

\captionsetup{
    format=plain,
    singlelinecheck=false,
    justification=raggedright,
    margin={.5cm, 0cm}
}

\counterwithin{figure}{section}
\counterwithin{table}{section}

\title{Kompilator języka strukturalnego}
\author{David Korenchuk}
\date{August, 23, 2023}

\begin{document}
    \pagestyle{fancy}
    \lhead{\leftmark}
    \rhead{\thetitle}
    
    \setlength{\parindent}{0pt}

    \maketitle
    
    \newpage
    
    \tableofcontents

    \newpage
	
	%% 1.   Wprowadzenie
	%% 2.   Teoria
	%% ...  Opis lex
	%% ...  Opis parse
	%% ...  Opis codegen
	%% ...  Opis interpreter
	%% N.   Podsumowanie. Co było zrobione
	
	\section{Wprowadzenie}
	
		Człowiek posługuje się językami werbalnymi, aby komunikować z innymi ludźmi. Za pomocą
		języka polskiego albo angielskiego można wyrazić myśl, ale zazwyczaj w sposób niejednoznaczny,
		bo jesteśmy przyzwyczajeni do tego, że każde zdanie może być wyrażone na wiele sposobów. Natomiast,
		aby umożliwić komunikację pomiędzy człowiekiem a komputerem, te zdania muszą być dość mocno
		sprecyzowane, aby móc je wykonać w sposób deterministyczny.
		\\
		
		Celem niniejszej pracy jest pokazanie technik, które są używane do umożliwiania takiego rodzaju
		komunikacji. Dalsza część pracy zawiera opis każdego z etapów tworzenia języka programowania
		strukturalnego. 

		\newpage
	
	\section{Historia}
		
		Potrzeba automatyzacji pracy intelektualnej istniała zawsze. Dlatego od dawna człowiek próbuje
		znaleźć metody do tego. Niżej jest krótkie podsumowanie powstania informatyki.
		\\
		
		\begin{itemize}
			\item W \textbf{IX} wieku
				przez irańskiego matematyka al Kindi wieku został stworzony system szyfrowania informacji na
				podstawie zliczania ilości liter w tekscie.

			\item W \textbf{XVII} wieku powstał suwak logarytmiczny, potrzebny do ułatwienia działań
				matematycznych.
			
			\item W tym samym \textbf{XVII} wieku powstał jeden z pierszych kalkulatorów mechanicznych
				\textbf{Pascalina}. Jest to narzędzie do wykonania operacji arytmetycznych na podstawie
				ruchu koł zębatych i innych części.
				
			\item W \textbf{XVIII} wieku Charlesa Babbage stworzył mechaniczną \textbf{maszynę
				różnicową} do tworzenia dużych tabeli logarytmicznych, które do tej pory człowiek
				musiał wyliczać ręcznie.
			
			\item W 1847 roku George Boole wyprowadził nowy rozdział algebry: \textbf{algebrę Boole'a},
				na podstawie której później został zaprojektowany pierwszy klasyczny komputer.
			
			\item W 1930 roku Vannevar Bush stworzył \textbf{analizator różnicowy} do rozwiązania
				równań różnicowych metodą całkowania.
			
			

		\end{itemize}

		\newpage
		
	\section{Teoria}

		\subsection{Języki formalne}

			Według teorii automatów, automat -- jest to jednostka wykonawcza. Jednostki te, zależnie od swojej
			struktury i tego, jaki \textbf{język formalny} oni mogą obrobić, dzielą się na klasy.
			\\
			
			Klasy te opisane są \textbf{hierarchią Chomsky’ego}. Mówi ona o tym, że języki formalne dzielą się na
			4 typy:
			\begin{itemize}
				\item Typ 3 -- języki regularne
				\item Typ 2 -- języki bezkontekstowe
				\item Typ 1 -- języki kontekstowe
				\item Typ 0 -- języki rekurencyjnie przeliczalne
			\end{itemize}
			
			\spacing

			Jako przykład języka typu 3 według hierarchii Chomsky'ego można podać wyrażenia regularne. Język ten
			opisuje się automatem skończonym deterministycznym (DFA). Bardziej szczegółowo wyrażenia regularne będą
			rozpatrzone w opisaniu analizy leksykalnej.
			
		\subsection{Klasyfikacja gramatyczna}

			Niniejszy język nie może być odniesiony do żadnej z klas hierarchii Chomsky'ego, chociaż jest on
			językiem regularnym. Tak jest dlatego, że można napisać gramatycznie poprawny kod, który jednak prowadzi
			do błędów kontekstowych i logicznych. Naprzykład 
			
			\spacing
			
			\begin{lstlisting}[caption={}, label={lst:ambigous-production}]
	void f() {
		 return argument + 1;
	}
			\end{lstlisting}

			\spacing
			
			Kolejną z przyczyn niemożliwości odniesienia naszego języka do jednej z klas hierarchii Chomsky'ego
			jest niejednoznaczność konstrukcji językowych. Przykład niżej pokazuje, że nie można jednoznacznie
			stwierdzić, czy \texttt{data * d} jest deklaracją zmiennej albo operatorem mnożenia dwóch zmiennych.
			Aby móc poprawnie prowadzić analizę składniową, musimy zadbać o rozróżnienie kontekstu.

			\spacing
			
			\begin{lstlisting}[caption={}, label={lst:ambigous-production}]
	void f() {
		 data *d;
	}
			\end{lstlisting}

			\newpage

	\section{Analiza leksykalna}

		Jednym ze sposobów na sprowadzanie kodu źródłowego do postaći listy tokenów jest narzędzie flex.
		Przyjmuje ono zestaw reguł w postaći wyrażeń regularnych, według których
		działa rozbicie tekstu wejściowego. Można jednak ominąć lex i zaimplemenetować lexer ręcznie, ale
		ta praca nie skupia się na tym.

		\subsection{Wyrażenia regularne}

			Wyrażenie regularne -- łańcuch znaków, zawierający pewne polecenia do wyszukiwania tekstu.
			\\

			Mówimy, że wyrażenie regularne określone nad alfabetem $\Sigma$, jeżeli zachodzą następujące
			warunki:

			\begin{itemize}
				\item $\emptyset$ -- wyrażenie regularne, reprezentujące pusty zbiór.
				\item $\epsilon$ -- wyrażenie regularne, reprezentujące pusty łańcuch.
				\item $\forall_{a \in \Sigma}$, $a$ reprezentuje jeden znak.
				\item Warunek indukcyjny: jeżeli $R_1, R_2$ -- wyrażenia regularne, $(R_1 R_2)$
				      stanowi konkatenację $R_1$ i $R_2$.
		      	\item Warunek indukcyjny: jeżeli $R$ -- wyrażenie regularne, $R*$ stanowi domknięcie Kleene'ego. 
			\end{itemize}

			\spacing

			W rzeczywistości, takich zasad może być więcej.
			\\

			Zazwyczaj wyrażenie regularne jest realizowane za pomocą DFA (Deterministic finite automaton,
			Deterministyczny automat skończony).
			Lex sprowadza podany zbiór zasad do takiego automatu.
			\\

			Podamy przykład automatu dla wyrażenia \texttt{-?[0-9]+}
			
			\spacing
			\spacing

			\begin{center}
			\begin{tikzpicture}[node distance=4cm]
				\node[state, initial, accepting] (0) {0};
				\node[state, right of=0]         (1) {1};
				\node[state, right of=1]         (2) {2};
				\draw
				(0) edge[       bend left ]             (1)
				(0) edge[below, bend right] node{$-$}   (1)
				(1) edge[below            ] node{$0-9$} (2)
				(2) edge[loop below       ] node{$0-9$} (2)
				;
			\end{tikzpicture}
			\end{center}
			
			Aby odśledzić wykonane kroki, można wypełnić tabelę przejść pomiędzy stanami. Podamy przykład dla
			łańcucha \texttt{-22}

			\spacing
			\spacing

		\begin{center}
			\setlength{\tabcolsep}{0.5em}
			\renewcommand{\arraystretch}{1.2}
			\begin{tabular}{ | L{3cm} | L{4cm} | }
				\hline
				Biężący stan        & Akcja \\
				\hline
				\textbf{0}          & zaakceptować - \\
				\hline
				0, \textbf{1}       & zaakceptować 2 \\
				\hline
				0, 1, \textbf{2}    & zaakceptować 2 \\
				\hline
			\end{tabular}
		\end{center}
		
		\newpage

	\subsection{Flex}

		Flex jest narzędziem projektu GNU. Pozwala ono w wygodny sposób podać listę reguł dla analizy
		leksykalnej (ang. Scanning). Flex jest mocno powiązany z językiem C, dlatego program w flex'u
		korzysta z konstrukcji języka C. Pokażemy przykład użycia flex'u
		
		\spacing
		
		\begin{lstlisting}[caption={Przykład użycia flex}, label={lst:flex-example}]
%{
#include "portrzebny-do-analizy-plik.h"

/* Kod w jezyku C. */
%}

/* Opcje flex */
%option noyywrap nounput noinput
%option yylineno

%% /* Reguly w postaci wyrazen regularnych. */

/*********************************************************************/
/* Wzorzec                   | Akcja przy znalezieniu takiego wzorcu */
/*********************************************************************/
-?[0-9]+                       LEX_CONSUME_WORD(TOK_INTEGRAL_LITERAL)
-?[0-9]+\.[0-9]+               LEX_CONSUME_WORD(TOK_FLOATING_POINT_LITERAL)
\"([^\"\\]*(\\.[^\"\\]*)*)\"   LEX_CONSUME_WORD(TOK_STRING_LITERAL)
\'.\'                          LEX_CONSUME_WORD(TOK_CHAR_LITERAL)

.                              { /* Znaleziony niewiadomy znak.
                                    Zglosic blad.
                                  */ }
%%
		\end{lstlisting}

		\spacing
		
		Zauważmy, że flex próbuje szukać wzorców w tekscie dokładnie w takiej kolejności, która jest podana w
		jego kodzie. Dlatego często robią ostatnią regułe z wyrażeniem regularnym ".", który akceptuje
		dowolny znak, i umieszczają tam komunikat o błędzie.
		\\

		W naszym przypadku, lex generuje kod, który gromadzi wszystkie znalezione lexemy do tablicy.

		\newpage

	\section{Analiza składniowa}
		
		\subsection{Definicja}

			Mając listę składników elementarnych wejściowego programu, jesteśmy w stanie przejść do
			następnego etapu kompilacji -- analizy składniowej. Jest to proces generacji struktury
			drzewiastej, a mianowicie AST (Abstract Syntax Tree).
			\spacing
			
			Wynikiem działania analizy składniowej zawsze jest \textbf{jedno} drzewo AST. Może zawieraić ono
			definicje wszystkich funkcji.
			\\
		
			AST może być stworzony po zdefiniowaniu gramatyki regularnej danego języka. Stosuje się
			do tego notacja BNF (Backus–Naur form). Pełny opis gramatyki pokazany jest w końcu pracy. Pokażemy
			tylko kilka przykładów:
			
			\spacing

		    \setlength{\grammarindent}{12em}

		    \begin{grammar}
		        <program> ::= ( <function-decl> | <structure-decl> )*

		        <var-decl> ::= <type> ( \tt{*} )* <id> \tt{=} <logical-or-stmt> \tt{;}

		        <stmt> ::= <block-stmt>
		        \alt <selection-stmt>
		        \alt <iteration-stmt>
		        \alt <jump-stmt>
		        \alt <decl>
		        \alt <expr>
		        \alt <assignment-stmt>
		        \alt <primary-stmt>
			\end{grammar}
			
			\spacing
			
			W przypadku wyrażeń arytmetycznych, AST także jednoznacznie określa za pomocą produkcji
			gramatyki BNF priorytet operacji
			arytmetycznych. Naprzykład, mając wyrażenie \ \texttt{1 + 2 * 3 + 4}, drzewo syntaksyczne
			będzie skonstruowane zgodnie z prawami arytmetyki, co pozwala nie trzymać w AST żadnych
			informacji o nawiasach. Widać, że aby zastosować produkcję \textit{$<$additive-stmt$>$},
			najpierw musi być zastosowana następna produkcja \textit{$<$multiplicative-stmt$>$}.
			\\

			Pomocnicza przy prowadzeniu analizy jest \textbf{tablica parsingu}. Jest to zbiór
			konkretnych przejść pomiędzy produkcjami. Pomaga ona w zrozumieniu, jaką
			produkcję zastosować mając dany nieterminal. Zauważmy, że w tabelę są wpisane produkcje bez
			alternatyw, i każde przejście gramatyczne określone jednoznacznie.
			\\
			
			Aby zbudować tą tablicy, możemy użyć zasady
			\textbf{First \& Follow}. Tutaj \textbf{First} to zbiór terminalnych symboli, które mogą pojawić
			się jako
			pierwsze w ciągu znaków wygenerowanym przez daną nieterminalną symbol w gramatyce,
			a \textbf{Follow} to
			zbiór terminalnych symboli, które mogą wystąpić bezpośrednio po danym nieterminalnym symbolu
			w dowolnym ciągu znaków wygenerowanym przez gramatykę.
			\\
			
			\newpage
			
			Podamy gramatykę dla przykładu powyżej (\texttt{1 + 2 * 3 + 4}). Musimy wprowadzić dwa poziomy
			priorytetów, aby prawidłowo zachować kolejność operacji mnożenia i dodawania.
			\\

			\begin{grammar}
		        <additive-stmt> ::= <multiplicative-stmt>
		        \alt <multiplicative-stmt> \tt{"+"} <additive-stmt>
		        \alt <multiplicative-stmt> \tt{"-"} <additive-stmt>

		        <multiplicative-stmt> ::= <prefix-unary-stmt>
		        \alt <prefix-unary-stmt> \tt{"*"} <multiplicative-stmt>
		        \alt <prefix-unary-stmt> \tt{"/"} <multiplicative-stmt>
		        \alt <prefix-unary-stmt> \tt{"%"} <multiplicative-stmt>
			\end{grammar}
			
			\spacing

			\begin{center}
				\setlength{\tabcolsep}{0.5em}
				\renewcommand{\arraystretch}{1.5}
				\begin{tabular}{ L{5cm} L{3cm} L{4cm} }
					                          & \textbf{First} & \textbf{Follow} \\
					$<$additive-stmt$>$       & 0-9            & \textbf{+}, \textbf{-} \\
					$<$multiplicative-stmt$>$ & 0-9            & \textbf{*}, \textbf{/} \\
					$<$prefix-unary-stmt$>$   & 0-9            & $\epsilon$ \\
				\end{tabular}
			\end{center}

			\spacing

			\begin{center}
				\setlength{\tabcolsep}{0.5em}
				\renewcommand{\arraystretch}{1.5}
				\begin{tabular}{ | L{4.1cm} | L{2cm} | L{2cm} | L{2cm} | L{2cm} | L{2cm} | L{2cm} | }
                  	\hline
                  	       & 0-9    & +    & -    & *    & /    & \$ \\
                  	\hline
              	 	$<$additive-stmt$>$
              	 	       &        & $<$mul$>$ + $<$add$>$
              	 	                & $<$mul$>$ - $<$add$>$
              	 	                & & & $<$mul$>$ \\
                  	\hline
                  	$<$multiplicative-stmt$>$ 
                  		   &        & & & $<$una$>$ * $<$mul$>$
                  		                & $<$una$>$ / $<$mul$>$
                  		                & $<$una$>$ \\
                  	\hline
                  	$<$prefix-unary-stmt$>$
                  	       & 0-9 & & & & & \\
                  	\hline
				\end{tabular}
			\end{center}

			\spacing

			\begin{center}
			\begin{tikzpicture}
				[level distance=1.5cm]
				\node[state] {+}
				child {
			  		node[state] {+}
			  		child { node[state] {\textbf{1}} }
			  		child {
			  			node[state] {*}
			  			child { node[state] {\textbf{2}} }
		  				child {node[state] {\textbf{3}} }
			  		}
		  		}
		  		child {
		  			node[state] {\textbf{4}}
		  		};
			\end{tikzpicture}
			\end{center}

		\subsection{Eliminacja rekurencji lewej}

			Projektując gramatykę, należy wziąć pod uwagę problem rekurencji lewej (Left recursion).
			Są produkcje gramatyczne, nie pozwalające kodu, które je implementuje przejść do następnego
			terminalu, stosując tą samą produkcję, co prowadzi do rekurencji nieskończonej.
			\\
			
			Rekuręcja lewa może wyglądać następująco:

		    \begin{grammar}
		    	<factor> ::= <factor> '+' <term>
			\end{grammar}

			\spacing

			Kod, wykonujący tą regułe będzie miał postać:
			
			\spacing

			\begin{lstlisting}[label={lst:left-recursion}]
void factor() {
	factor(); // Rekurencja bez zadnego warunku wyjscia
	consume('+');
	term();
}
			\end{lstlisting}
		
		\subsection{Niejednoznaczność}
		
			Projektując język, łatwo trafić na niejednoznaczne produkcje gramatyczne. One są takie, że
			jednego tekstu wejściowego są one w stanie wyprodukować kilka różnych od siebie drzew. Popularny
			warunek dla stworzenia niejednoznaczności to taka produkcja
			
			\begin{grammar}
		        <P> ::= <P> + <P>
				\alt <symbol>
			\end{grammar}
			
			
			Po zastosowaniu danej produkcji dla \texttt{A + B + C} możliwe jest otrzymanie dwóch drzew
			
			\spacing
			\spacing

			\begin{center}
				\begin{tabular}{ L{5cm} L{5cm} }
					\begin{tikzpicture}
						[level distance=1.5cm]
						\node[state] {+}
						child {
					  		node[state] {+}
					  		child { node[state] {\textbf{A}} }
					  		child { node[state] {\textbf{B}} }
				  		}
				  		child {
				  			node[state] {\textbf{C}}
				  		};
					\end{tikzpicture}
					&
					\begin{tikzpicture}
						[level distance=1.5cm]
						\node[state] {+}
						child {
				  			node[state] {\textbf{A}}
				  		}
				  		child {
					  		node[state] {+}
					  		child { node[state] {\textbf{B}} }
					  		child { node[state] {\textbf{C}} }
				  		};
					\end{tikzpicture}
				\end{tabular}
			\end{center}
			
			Aby rozwiązać ten problem i jednoznacznie wskazać kolejność zastosowania reguł gramatycznych,
			możemy zamienić prawy operand na symbol, wtedy eliminuje się dwuznaczność. Pierwsza produkcja
			poniżej jest \textbf{lewostronną}, a druga -- \textbf{prawostronną}.

			\begin{grammar}
		        <P> ::= <P> + <symbol>
	
		        <P> ::= <symbol> + <P>
			\end{grammar}

			\newpage

		\subsection{Implementacja AST}

			Zaimplementowany AST składa się ze struktury \texttt{ast_node}. Jest to główny typ
			węzła, zawierający niektóre zbędne informacje dla każdego typu węzła AST, i przechowujący
			konkretny węzęł jako wskaźnik.

			\spacing

			\begin{lstlisting}[label={lst:ast-node}]
struct ast_node {
    enum ast_type  type;    /* Rozrozniamy typ wedlug tej flagi */
    void          *ast;     /* ast_num, ast_for, ast_while, et cetera */
    uint16_t       line_no;
    uint16_t       col_no;
};
			\end{lstlisting}
			
			\spacing
			
			Konkretne węzły definiujemy w następujący sposób:

			\spacing

			\begin{lstlisting}[label={lst:ast-concrete-node}]
struct ast_num {
    int32_t value;
};
			\end{lstlisting}
			
			\spacing
			
			Taki AST stanowi strukturę drzewiastą, mającą wszystkie zalety i wady drzew jako struktur
			danych. Mając takie drzewo, jesteśmy w stanie prowadzić zwykłe przeszukiwanie w głąb
			i wszerz. W danym przypadku taki algorytm się nazywa \textbf{AST visitor}. Dokładnie w ten
			sposób działa każda z przedstawionych niżej analiz semantycznych
			oraz generacja kodu pośredniego.

			\spacing

			\begin{algorithm}
				\caption{Przeszukiwanie AST}
				\begin{algorithmic}[1]

				\Procedure{DFS}{AST}
					\For{each child node Child of AST}
						\State DFS(Child)
					\EndFor
				\EndProcedure

				\end{algorithmic}
			\end{algorithm}

		\subsection{Implementacja analizatora składniowego}
			
			W danym przypadku, analizator składniowy jest napisany ręcznie, chociaż są narzędzia od
			projektu GNU, takie jak GNU Bison i UNIX'owe, takie jak YACC. Niniejszy analizator
		  	jest napisany bez pomocy tych programów, aby jawnie pokazać, jak się przekładają
		  	produkcje BNF na język C.
		  	\\
		  	
		  	Aby poradzić sobie z zadaniem pisania takiego analizatora, możemy zauważyć, że
		  	zadanie to sprowadza się do implementacji każdej produkcji gramatycznej osobno.
	  	
	  	\subsection{Reprezentacja wizualna AST}
	  		
	  		Jest pokazana też implementacja \textbf{visitor}'u, pozwalającego na przeprowadzenie AST
			do formy tekstowej. Do tego służy funkcja \textbf{ast_dump()}. Przyjmuje ona wskaźnik do
			węzła drewa i działa według algorytmu DFS, opisanego wyżej, przy tym pisząc tekstową formę
			węzłów do pliku (ewentualnie, do \texttt{stdout}). Funkcjonalność ta jest bardzo ważna do
			prowadzenia testów jednostkowych samego AST oraz analizatoru składniowego.
			Niżej pokazany jest przykładowy wynik działania tej funkcji.
			\\
	
			\begin{lstlisting}[label={lst:ast-text}]
CompoundStmt <line:0, col:0>
  StructDecl <line:9, col:1> `custom`
    CompoundStmt <line:9, col:1>
      VarDecl <line:10, col:5> int `a`
      VarDecl <line:11, col:5> int `b`
      VarDecl <line:12, col:5> int `c`
      ArrayDecl <line:13, col:5> char [1000] `mem`
      VarDecl <line:14, col:5> struct string `description`
			\end{lstlisting}
	
	\section{Analiza semantyczna}

		Aby zapewnić poprawność napisanego kodu, stosuje się wiele rodzajów analiz. Niniejszy kompilator
		dysponuje trzema:
		
		\begin{itemize}
			\item Analiza nieużytych zmiennych, oraz zmiennych, które są zdefiniowane, ale nie zostały użyte
			\item Analiza poprawności typów
			\item Analiza prawidłowego użycia funkcji
		\end{itemize}
		
		\subsection{Analiza nieużywanych zmiennych}
			
			Podamy przykłady kodu prowadzącego do odpowiednich ostrzeżeń
			
			\spacing

			\begin{lstlisting}[label={lst:warn-unused-var}]
void f() {
	int argument = 0; // Warning: unused variable `argument`
}
			\end{lstlisting}

			\begin{lstlisting}[label={lst:warn-unused-var}]
void f(int argument) { // Warning: unused variable `argument`

}
			\end{lstlisting}
			
			\begin{lstlisting}[label={lst:warn-unused-var}]
void f() {
	int argument = 0;
	++argument; // Warning: variable `argument` written, but never read
}
			\end{lstlisting}

			%% (\ref{lst:warn-unused-var})
			
			\spacing
			
			Rzecz polega na przejściu drzewa syntaksycznego i zwiększania liczników
			\textbf{read_uses} i \textbf{write_uses} dla każdego węzła typu
			\textbf{ast_sym}.
			\\
			
			Algorytm operuje na blokach kodu, zawartego w \textbf{\{ ... \}}. Po przejściu każdego bloku
			(w tym rekurencyjnie), analiza jest wykonana w następujący sposób:

			\begin{algorithm}
				\caption{Wyszukiwanie nieużywanych zmiennych}
				\begin{algorithmic}[1]

				\Procedure{Analyze}{AST}
					\State Set $\gets$ all declarations at current scope depth

					\For{each collected declaration Use in Set}
						\If{Use is not a function \& Use.ReadUses is 0}
							\State Emit warning
						\EndIf
					\EndFor
				\EndProcedure

				\end{algorithmic}
			\end{algorithm}
			
			Do analizy nieużywanych funkcji stosuje się tem sam algorytm. Jedyne, co jest wtedy zmienione --
			sprawdzenie, czy nazwa rozpatrywanej funkcji nie jest \textbf{main}. Funkcja \textbf{main} jest
			wywołana automatycznie.
		
		\section{System typów}
		
			\subsection{Opis}

				Wiele zasad, dotyczących pracy z typami mogą być precyzyjnie opisane zasadami typów
				(\textbf{Typing rules}). Jest to notacja matematyczna, znaczenie której niżej wyjaśnimy.
				\\
				
				Kluczowym pojęciem w tej notacji jest \textbf{statyczne środowisko typów}
				(\textbf{static typing environment}). Oznacza się ono symbolem $\Gamma$. Mówimy, że to
				środowisko jest skonstruowane poprawnie pisząc $$\Gamma \vdash \diamond$$
				
				Mówimy, że zmienna \textbf{V} ma typ \textbf{T} w środowisku $\Gamma$ pisząc
				$$\Gamma \vdash \text{V} : T$$
				
				Kreska pozioma mówi o tym, że zdanie wyżej jest konieczne, aby zaszło zdanie niżej

				\begin{mathpar}
				\inferrule
				  {\Gamma \vdash \diamond}
				  {\Gamma \vdash \text{V} : T}
				\end{mathpar}
				
				\spacing
				
				Zauważmy, że notacja ta jest mocnyn narzędziem, pozwalającym opisać dość złożone systemy typów
				dla takich języków jak \textbf{C++} i \textbf{Haskell}.
			
			\subsection{Definicja systemu}

				Opiszmy teraz system typów w naszym języku

				\begin{mathpar}
				\inferrule
				  {\Gamma \vdash \diamond}
				  {\Gamma \vdash \text{true} : bool}
				\quad

				\inferrule
				  {\Gamma \vdash \diamond}
				  {\Gamma \vdash \text{false} : bool}
				\end{mathpar}

				\begin{mathpar}
				\inferrule
				  {\Gamma \vdash \diamond}
				  {\Gamma \vdash \text{n} : int}
				\end{mathpar}

				\begin{mathpar}
				\inferrule
				  {\Gamma \vdash \diamond}
				  {\Gamma \vdash \text{c} : char}
				\end{mathpar}

				\begin{mathpar}
				\inferrule
				  {\Gamma \vdash \diamond}
				  {\Gamma \vdash \text{x} : float}
				\end{mathpar}

			Oznaczmy dla $\mathbb{N, R}: \oplus \in \{ =, +, -, *, /, <, >, \le, \ge, ==, \neq, ||, \&\& \}$, wtedy

				\spacing

				\begin{mathpar}
				\inferrule
				  {\Gamma \vdash e_l : float \\ \Gamma \vdash e_r : float}
				  {\Gamma \vdash e_l \oplus e_r : float}
				\end{mathpar}

				\spacing

			Dodamy do $\oplus$ operacje tylko dla $\mathbb{N}: \oplus \ \cup \ \{ |, \&, \string^, <<, >>, \% \}$, wtedy

				\spacing

				\begin{mathpar}
				\inferrule
				  {\Gamma \vdash e_l : int \\ \Gamma \vdash e_r : int}
				  {\Gamma \vdash e_l \oplus e_r : int}

				\inferrule
				  {\Gamma \vdash e_l : int \\ \Gamma \vdash e_r : char}
				  {\Gamma \vdash e_l \oplus e_r : char}
				\end{mathpar}

				\spacing

				Wprowadźmy reguły niejawnej konwersji, które są niezbędne przy sprawdzaniu w warunku
				logicznym wyniku operacji arytmetycznej, zwracającej typ różny od
				\texttt{bool}. Oznaczmy reguły dla typów \texttt{int}, \texttt{char} i \texttt{float}.

				\spacing
				
				\begin{mathpar}
				\inferrule
					{\Gamma \vdash \text{e} : int}
					{\Gamma \vdash \text{e} : bool}

				\inferrule
					{\Gamma \vdash \text{e} : char}
					{\Gamma \vdash \text{e} : bool}

				\inferrule
					{\Gamma \vdash \text{e} : float}
					{\Gamma \vdash \text{e} : bool}
				\end{mathpar}

				\spacing
				
				Wprowadźmy także reguły do operacji wskaźnikowych. Oznaczmy
				$\oplus \in \{ =, +, -, \ \le, \ge, ==, \neq \}$, wtedy
				
				\spacing
				
				\begin{mathpar}
				\inferrule
					{\Gamma \vdash e_l : int \ * \\ \Gamma \vdash e_r : int \ *}
					{\Gamma \vdash e_l \oplus e_r : int \ *}

				\inferrule
					{\Gamma \vdash e_l : char \ * \\ \Gamma \vdash e_r : char \ *}
					{\Gamma \vdash e_l \oplus e_r : char \ *}

				\inferrule
					{\Gamma \vdash e_l : float \ * \\ \Gamma \vdash e_r : float \ *}
					{\Gamma \vdash e_l \oplus e_r : float \ *}
	
				\inferrule
					{\Gamma \vdash e_l : bool \ * \\ \Gamma \vdash e_r : bool \ *}
					{\Gamma \vdash e_l \oplus e_r : bool \ *}
				\end{mathpar}

				\spacing

				Mając taką konwersję, możemy wprowadzić reguły do konstrukcji warunkowych: 

				\spacing

				\begin{mathpar}
				\inferrule
				  {\Gamma \vdash \text{condition} : bool \\ \Gamma \vdash e_1 : \tau \\ \Gamma \vdash e_2 : \tau}
				  {\Gamma \vdash \text{if (condition) } \{ \ e_1 \ \}  \text{ else }  \{ \ e_2 \ \} : \tau}
				\end{mathpar}

				\begin{mathpar}
				\inferrule
					{\Gamma \vdash \text{condition} : bool \\ \Gamma \vdash e : \tau}
					{\Gamma \vdash \text{while (condition) } \{ \ e \ \} : \tau}
				\end{mathpar}

				\begin{mathpar}
				\inferrule
					{\Gamma \vdash \text{condition} : bool \\ \Gamma \vdash e : \tau}
					{\Gamma \vdash \text{do } \{ \ e \ \} \text{ while (condition)} : \tau}
				\end{mathpar}

				\begin{mathpar}
				\inferrule
					{\Gamma \vdash \text{init} : \tau_1 \\
					 \Gamma \vdash \text{condition} : bool \\
					 \Gamma \vdash \text{increment} : \tau_2 \\ \Gamma \vdash e : \tau_3}
					{\Gamma \vdash \text{for (init; condition; increment) } \{ \ e \ \} : \tau_3}
				\end{mathpar}

	\section{Generacja kodu pośredniego}
		
		Kod pośredni -- jest to język, składający się z elementarnych operacji nad danymi, takimi jak
		arytmetyczne operacje, zapisanie do komórki pamięci.
		\\
		
		Im prostszy ten język jest, tym prostsze
		są algorytmy do analizy, optymalizacji i generacji dalszych warstw pośrednich.
		\\
		
		Istnieje wiele różnych podobnych do assemblera języków (Intermediate representation, \textbf{IR}), służącego
		do generacji kodu maszynowego (LLVM IR, GIMPLE, FIRM). Jednak, niniejszy język implementuje własny IR z
		kilku powodów:
		
		\begin{itemize}
			\item Jest prostszy
			\item Ma prostszy interfejs programistyczny
			\item Nie stanowi dodatkowych zależności jako biblioteki
			\item Ma na celu pokazanie metod na tworzenie takiego języka i operacje nad nimi
		\end{itemize}

	\section{Optymalizacje kodu pośredniego}
		
		Optymalizacja -- to zmiana kodu programu, mająca na celu polepszyć wydajność albo inne cechy
		programu. Najważniejym z kriteria optymalizacji jest utrzymanie całej struktury działania programu,
		takiej, jak chce programista. Nie wolno przeprowadzać wiodące do niespodziewanych lub
		niepoprawnych wyników optymalizacje.
		\\
		
		Istnieje wiele rodzajów optymalizacji, gdzie każda wymaga więcej lub mniej założeń i
		matematyki. Jeżeli chodzi o matematykę, to główną rolę w optymalizacji pełni \textbf{teoria grafów}.
		Jednym z pierwszych naukowców, kto zadecydował wprowadzić modele grafowe do kompilatorów był
		\textbf{Robert Tarjan}. Wprowadził także on algorytm do obliczenia drzewa dominatorów (dominator tree),
		co przyda nam się później.

		\subsection{Definicje}
			Każdy program posiadą taką cechę jak \textbf{przepływ sterowania}, i może ona być dość
			precyzyjnie wyrażona \textbf{grafem przepływu sterowania} (Control Flow Graph). Program
			rozpatrywany jest jako graf skierowany, posiadający wierzchołek startowy, będący pierwszą
			instrukcją w programie. Krawędzie reprezentują przejście pomiędzy instrukcjami. Zauważmy,
			że każda instrukcja może mieć wiele krawędzi wejściowych i wyjściowych, tworząc \textbf{gałęzi}
			w wykonaniu programu.
			\\
			
			Oznaczmy kilka ważnych pojęć.
			\\

			Niech $G = (V, E, s)$ -- graf skierowany.
			$V$ -- zbiór wierzchołków. $E$ -- zbiór krawędzi. $s$ -- węzęł początkowy.
			$G' = (V', E') \subseteq G$ -- podgraf, gdzie każdy wierzchołek $v \in G'$ jest nieosiągalny z
			dowolnej ścieżki $(s, ...,  v) \in G$. Zauważmy, że $G'$ może być grafem rozłącznym.

			$$V' = \{ \ v \ | \ \forall \ v \ \nexists \ (s, ..., v) \ \}$$

			\spacing

			Niech $G = (V, E, s)$ -- graf skierowany, zdefiniowany powyżej. Graf zależności danych -- graf
			$G' = (V', E', D')$. Wtedy $D' = \{ \ d, d' \in V' \ | \ d \rightarrow d' \ \}$. Przez $d \rightarrow d'$
			oznaczona zależnośc $d$ od wyniku obliczenia $d'$. Zbiór $D'$ reprezentuje takie zależności, przy czym
			dodatkowo musi być spełnione

			$$d, d' \in V', \ v \rightarrow v' \iff \exists \ (v', ..., v) \in G' $$
	
		\subsection{Constant propagation}
		
			Został zaimplementowany algorytm przeliczania stałych. Rozpatruje on każdy block CFG osobno,
			co pozwala na przeprowadzenie lokalnych optymalizacji. Niniejszy algorytm nie usuwa zmiennych,
			których nie potrzebuje po obliczeniach dlatego, że to jest obowiązek innej optymalizacji
			(\textbf{dead code elimination}). 

			\spacing
		
			\begin{algorithm}
				\caption{Przeliczenie zmiennych stałych}
				\begin{algorithmic}[1]

				\Procedure{ConstProp}{AST}
					\State Consts $\gets$ $\emptyset$
					
					\For{each statement S across all CFG blocks}
						\If{new CFG block is reached}
							\State Consts $\gets$ $\emptyset$
							\Comment Reset optimizer state
						\EndIf
						\If{S is binary}
							\State Consts $\gets$ Consts $\cup$ computed value of binary expression
						\EndIf
						\If{S is store}
							\If{S stores immediate}
								\If{Consts has value for S.Sym}
									\State Update Consts with new value
								\Else
									\State Consts $\gets$ Consts $\cup$ value
								\EndIf
							\EndIf
							\If{S stores symbol}
								\If{Consts has value for S.Sym}
									\State Update Consts with new value
								\Else
									\State Consts $\gets$ Consts $\backslash$ \{ value \}
								\EndIf
							\EndIf
						\EndIf
					\EndFor
				\EndProcedure

				\end{algorithmic}
			\end{algorithm}
		
		\newpage

		\subsection{Unreachable code elimination}
		
			Usuwanie kodu nieosiągalnego polega na dwóćh krokach.
			\begin{itemize}
				\item Obejście grafu sterowania programu (\textbf{CFG})
				\item Usuwanie wszystkich instrukcji, do których nie ma żadnych wejściowych krawędzi.
			\end{itemize}
			
			\spacing

			Algorytm polega na zlalezieniu takich \textbf{podgrafów} grafu sterowania programem, do których
			nie prowadzi żadna z krawędzi.
			
			\spacing

			\begin{algorithm}
				\caption{Usuwanie kodu nieosiągalnego}
				\begin{algorithmic}[1]
					\Procedure{Eliminate}{CFG}
						\State Visited $\gets$ $\emptyset$
						\State \Call{Traverse}{Visited, CFG, First(CFG)}
						\State Unvisited $\gets$ CFG $\setminus$ Visited
						\State \Call{Cut}{Unvisited, CFG}
					\EndProcedure
					\\
					\Procedure{Traverse}{Visited, CFG, IR}
						\State Visited[IR] $\gets$ 1
						\For{each control flow successor of IR}
							\State \Call{Traverse}{Visited, CFG, Succ(IR)}
						\EndFor
					\EndProcedure
					\\
					\Procedure{Cut}{Unvisited, CFG}
						\For{each unvisited statement}
							\State Remove statement from IR
						\EndFor
					\EndProcedure
				\end{algorithmic}
			\end{algorithm}

		\newpage

	\section{Interpreter}

		% https://tex.stackexchange.com/questions/235000/drawing-an-activation-stack-in-latex

	\section{Annex: Gramatyka w BNF}

        \setlength{\grammarindent}{12em}

        \begin{grammar}
            <program> ::= ( <function-decl> | <structure-decl> )*

            <structure-decl> ::= \tt{struct} \tt{\{} <structure-decl-list> \tt{\}}

            <structure-decl-list> ::= (
            <decl-without-initialiser> \tt{;}
            \alt <structure-decl> \tt{;}
            )*

            <function-decl> ::= <ret-type> <id> \tt{(} <parameter-list-opt> \tt{)} \tt{\{} <stmt>* \tt{\}}

            <ret-type> ::= <type>
            \alt <void-type>

            <type> ::= \tt{int}
            \alt \tt{float}
            \alt \tt{char}
            \alt \tt{string}
            \alt \tt{boolean}

            <void-type> ::= \tt{void}

            <constant> ::= <integral-literal>
            \alt <floating-literal>
            \alt <string-literal>
            \alt <char-literal>
            \alt <boolean-literal>

            <integral-literal> ::= <digit>*
            
            <floating-literal> ::= <digit>* \tt{.} <digit>*

            <string-literal> ::= ''\tt{( "x00000000-x0010FFFF" )*}''

            <char-literal> ::= '\tt{ASCII(0)}-\tt{ASCII(127)}'

            <boolean-literal> ::= \tt{true}
            \alt \tt{false}

            <alpha> ::= \tt{a} | \tt{b} | ... | \tt{z} | \tt{_}

            <digit> ::= \tt{0} | \tt{1} | ... | \tt{9}

            <id> ::= <alpha> ( <alpha> | <digit> )*

            <array-decl> ::= <type> ( \tt{*} )* <id> \tt{[} <integral-literal> \tt{]}

            <var-decl> ::= <type> ( \tt{*} )* <id> \tt{=} <logical-or-stmt> \tt{;}
            
            <structure-var-decl> ::= <id> ( \tt{*} )* <id>

            <decl> ::= <var-decl>
            \alt <array-decl>
            \alt <structure-var-decl>

            <decl-without-initialiser> ::= <type> ( \tt{*} )* <id>
            \alt <array-decl>
            \alt <structure-var-decl>

            <parameter-list> ::= <decl-without-initialiser> \tt{,} <parameter-list>
            \alt <decl-without-initialiser>

            <parameter-list-opt> ::= <parameter-list> | $\epsilon$

            <stmt> ::= <block-stmt>
            \alt <selection-stmt>
            \alt <iteration-stmt>
            \alt <jump-stmt>
            \alt <decl>
            \alt <expr>
            \alt <assignment-stmt>
            \alt <primary-stmt>
            
            <member-access-stmt> ::= <id> \tt{.} <member-access-stmt>
            \alt <id> \tt{.} <id>

            <iteration-stmt> ::= <stmt>
            \alt \tt{break};
            \alt \tt{continue};
            
            <block-stmt> ::= \tt{\{} <stmt>* \tt{\}}
            
            <iteration-block-stmt> ::= \tt{\{} <iteration-stmt>* \tt{\}}

            <selection-stmt> ::= \tt{if} \tt{(} <expr> \tt{)} <block-stmt>
            \alt \tt{if} \tt{(} <expr> \tt{)} <block-stmt> \tt{else} <block-stmt>

            <iteration-stmt> ::= \tt{for} \tt{(} <expr-opt> \tt{;} <expr-opt> \tt{;} <expr-opt> \tt{)} <iteration-block-stmt>
            \alt \tt{for} \tt{(} <decl> \tt{:} <symbol-stmt> \tt{)} <iteration-block-stmt>
            \alt \tt{while} \tt{(} <expr> \tt{)} <iteration-block-stmt>
            \alt \tt{do} <iteration-block-stmt> \tt{while} \tt{(} <expr> \tt{)} \tt{;}

            <jump-stmt> ::= \tt{return} <expr> ? \tt{;}

            <assignment-op> ::= \tt{=}
            \alt \tt{*=}
            \alt \tt{/=}
            \alt \tt{\%=}
            \alt \tt{+=}
            \alt \tt{-=}
            \alt \tt{"<<="}
            \alt \tt{">>="}
            \alt \tt{\&=}
            \alt \tt{|=}
            \alt \tt{"^="}

            <expr> ::= <assignment-stmt>
            \alt <var-decl>

            <expr-opt> ::= <expr> | $\epsilon$

            <assignment-stmt> ::= <logical-or-stmt>
            \alt <logical-or-stmt> <assignment-op> <assignment-stmt>

            <logical-or-stmt> ::= <logical-and-stmt>
            \alt <logical-and-stmt> \tt{||} <logical-or-stmt>

            <logical-and-stmt> ::= <inclusive-or-stmt>
            \alt <inclusive-or-stmt> \tt{\&\&} <logical-and-stmt>

            <inclusive-or-stmt> ::= <exclusive-or-stmt>
            \alt <exclusive-or-stmt> \tt{|} <inclusive-or-stmt>

            <exclusive-or-stmt> ::= <and-stmt>
            \alt <and-stmt> \tt{"^"} <exclusive-or-stmt>

            <and-stmt> ::= <equality-stmt>
            \alt <equality-stmt> \tt{\&} <and-stmt>

            <equality-stmt> ::= <relational-stmt>
            \alt <relational-stmt> \tt{==} <equality-stmt>
            \alt <relational-stmt> \tt{!=} <equality-stmt>

            <relational-stmt> ::= <shift-stmt>
            \alt <shift-stmt> \tt{">"} <relational-stmt>
            \alt <shift-stmt> \tt{"<"} <relational-stmt>
            \alt <shift-stmt> \tt{">="} <relational-stmt>
            \alt <shift-stmt> \tt{"<="} <relational-stmt>

            <shift-stmt> ::= <additive-stmt>
            \alt <additive-stmt> \tt{"<<"} <shift-stmt>
            \alt <additive-stmt> \tt{">>"} <shift-stmt>

            <additive-stmt> ::= <multiplicative-stmt>
            \alt <multiplicative-stmt> \tt{"+"} <additive-stmt>
            \alt <multiplicative-stmt> \tt{"-"} <additive-stmt>

            <multiplicative-stmt> ::= <prefix-unary-stmt>
            \alt <prefix-unary-stmt> \tt{"*"} <multiplicative-stmt>
            \alt <prefix-unary-stmt> \tt{"/"} <multiplicative-stmt>
            \alt <prefix-unary-stmt> \tt{"%"} <multiplicative-stmt>

            <prefix-unary-stmt> ::= <postfix-unary-stmt>
            \alt \tt{++} <postfix-unary-stmt>
            \alt \tt{--} <postfix-unary-stmt>
            \alt \tt{*} <postfix-unary-stmt>
            \alt \tt{\&} <postfix-unary-stmt>
            \alt \tt{!} <postfix-unary-stmt>

            <postfix-unary-stmt> ::= <primary-stmt>
            \alt <primary-stmt> \tt{++}
            \alt <primary-stmt> \tt{--}

            <primary-stmt> ::= <constant>
            \alt <symbol-stmt>
            \alt \tt{(} <logical-or-stmt> \tt{)}
            
            <symbol-stmt> ::= <function-call-stmt>
            \alt <array-access-stmt>
            \alt <member-access-stmt>
            \alt <id>
            
            <array-access-stmt> ::= <id> ( \tt{[} <expr> ] )*
            
            <function-call-arg-list> ::= <logical-or-stmt> \tt{,} <function-call-arg-list>
            \alt <logical-or-stmt>
            
            <function-call-arg-list-opt> ::= <function-call-arg-list> | $\epsilon$

            <function-call-expr> ::= <id> \tt{(} <function-call-arg-list-opt> \tt{)}

        \end{grammar}

		\newpage

	\begin{thebibliography}{9}
		\bibitem{texbook}
			https://www.bates.edu/biology/files/2010/06/How-to-Write-Guide-v10-2014.pdf
		
		\bibitem{texbook}
			Bauer, Friedrich Ludwig,
			\emph{Compiler construction},
			1974, Berlin,
			ISBN: 3-540-06958-5
		
		\bibitem{texbook}
			http://lucacardelli.name/papers/typesystems.pdf
	
		\bibitem{texbook}
			https://gcc.gnu.org/onlinedocs/gccint/GIMPLE.html

		\bibitem{texbook}
			https://llvm.org/docs/LangRef.html

		\bibitem{texbook}
			https://github.com/libfirm/libfirm
	\end{thebibliography}

\end{document}